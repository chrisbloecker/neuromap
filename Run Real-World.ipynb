{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred                     import PygNodePropPredDataset\n",
    "from pathlib                              import Path\n",
    "from sklearn.metrics                      import adjusted_mutual_info_score\n",
    "from torch_geometric.data                 import Data\n",
    "from torch_geometric.datasets             import Amazon, Coauthor, Planetoid\n",
    "from torch_geometric_signed_directed.data import Cora_ml, WikiCS\n",
    "from training                             import Neuromap, DMoN, MinCut, Ortho, DiffPool, NOCD\n",
    "from util                                 import *\n",
    "\n",
    "import json\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import seaborn as sb\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"550\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#0173b2;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#de8f05;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#029e73;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d55e00;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#cc78bc;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ca9161;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fbafe4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#949494;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ece133;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"495\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#56b4e9;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.00392156862745098, 0.45098039215686275, 0.6980392156862745),\n",
       " (0.8705882352941177, 0.5607843137254902, 0.0196078431372549),\n",
       " (0.00784313725490196, 0.6196078431372549, 0.45098039215686275),\n",
       " (0.8352941176470589, 0.3686274509803922, 0.0),\n",
       " (0.8, 0.47058823529411764, 0.7372549019607844),\n",
       " (0.792156862745098, 0.5686274509803921, 0.3803921568627451),\n",
       " (0.984313725490196, 0.6862745098039216, 0.8941176470588236),\n",
       " (0.5803921568627451, 0.5803921568627451, 0.5803921568627451),\n",
       " (0.9254901960784314, 0.8823529411764706, 0.2),\n",
       " (0.33725490196078434, 0.7058823529411765, 0.9137254901960784)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette = sb.color_palette(\"colorblind\")\n",
    "sb.color_palette(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run( data\n",
    "       , methods = [Neuromap]\n",
    "       , models  = [ (\"lin\",  [1e-1])\n",
    "                   , (\"mlp\",  [1e-2])\n",
    "                   , (\"gin\",  [1e-3])\n",
    "                   , (\"gcn\",  [1e-3])\n",
    "                   , (\"sage\", [1e-3])\n",
    "                   ]\n",
    "       , num_trials      : int  = 25\n",
    "       , lr_schedule     : bool = False\n",
    "       , verbose         : bool = False\n",
    "       , fixed_size_arch : bool = False\n",
    "       ):\n",
    "    y_true = data.y.cpu().numpy()\n",
    "\n",
    "    if fixed_size_arch:\n",
    "        hidden_channels = 512\n",
    "        out_channels    = data.num_classes\n",
    "    else:\n",
    "        hidden_channels = int(round(4*np.sqrt(data.num_nodes)))\n",
    "        out_channels    = int(round(np.sqrt(data.num_nodes)))\n",
    "\n",
    "    res_str = \"method,arch,avg ami,std ami,avg m,std m\\n\"\n",
    "\n",
    "    for model, lrs in models:\n",
    "        print(model)\n",
    "        print(\"=====\")\n",
    "        for C in methods:\n",
    "            out = Path(f\"./results/real-world{'-fixed-size-arch' if fixed_size_arch else ''}/{C.__name__}-{model}-{data.name}.json\")\n",
    "\n",
    "            if out.exists():\n",
    "                with open(out, \"r\") as fh:\n",
    "                    res = json.load(fh)\n",
    "            else:\n",
    "                res = dict()\n",
    "            \n",
    "            for trial in range(1, num_trials + 1):\n",
    "                if str(trial) not in res:\n",
    "                    clusterer = C(device = device, use_model = model, in_channels = data.num_node_features, hidden_channels = hidden_channels, out_channels = out_channels, num_layers = 2, dropout = 0.5)\n",
    "                    l, s      = clusterer.fit(data = data, epochs = 10000, patience = 100, lrs = lrs, lr_schedule = lr_schedule, num_trials = 1, verbose = verbose)\n",
    "                    if l is not None and s is not None:\n",
    "                        y_pred = get_hard_clusters(s)\n",
    "\n",
    "                        ami = adjusted_mutual_info_score(y_true, y_pred)\n",
    "                        m   = len(set(y_pred))\n",
    "\n",
    "                        res[str(trial)] = dict(loss = l, y_pred = y_pred, ami = ami, m = m)\n",
    "\n",
    "                        with open(out, \"w\") as fh:\n",
    "                            json.dump(res, fh)\n",
    "        \n",
    "            if len(res) > 0:\n",
    "                best_result = min(res.values(), key = lambda r: r[\"loss\"])\n",
    "                avg_ami     = np.average([v['ami'] for v in res.values()])\n",
    "                std_ami     = np.std([v['ami'] for v in res.values()])\n",
    "                avg_m       = np.average([v['m'] for v in res.values()])\n",
    "                std_m       = np.std([v['m'] for v in res.values()])\n",
    "                print(f\"[{C.__name__:10}] <AMI> = {100 * avg_ami:4.1f} ± {100 * std_ami:4.1f}, <|M|> = {avg_m:6.1f} ± {std_m:6.1f}, AMI* = {100 * best_result['ami']:4.1f}, |M|* = {best_result['m']:6}\")\n",
    "                res_str += f\"{C.__name__},{model},{100 * avg_ami:.1f},{100 * std_ami:.1f},{avg_m:.1f},{std_m:.1f}\\n\"\n",
    "    \n",
    "    with open(f\"./results/real-world{'-fixed-size-arch' if fixed_size_arch else ''}/{data.name}.csv\", \"w\") as fh:\n",
    "        fh.write(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_infomap(data, directed, num_trials = 25, fixed_size_arch = False):\n",
    "    G      = data_to_networkx(data, directed = directed)\n",
    "    y_true = data.y.cpu().numpy()\n",
    "\n",
    "    np.random.seed(47)\n",
    "    seeds = np.random.randint(0,100000, size = 25)\n",
    "\n",
    "    out = Path(f\"./results/real-world{'-fixed-size-arch' if fixed_size_arch else ''}/Infomap-{data.name}.json\")\n",
    "\n",
    "    if out.exists():\n",
    "        with open(out, \"r\") as fh:\n",
    "            res = json.load(fh)\n",
    "    else:\n",
    "        res = dict()\n",
    "\n",
    "    for trial, seed in enumerate(seeds, start = 1):\n",
    "        if str(trial) not in res:\n",
    "            im = Infomap(silent = True, two_level = True, num_trials = 1, seed = seed)\n",
    "            im.add_networkx_graph(G)\n",
    "            im.run()\n",
    "            modules = dict(im.modules)\n",
    "\n",
    "            y_pred = [modules[u] for u in sorted(G.nodes)]\n",
    "            ami    = adjusted_mutual_info_score(y_true, y_pred)\n",
    "            m      = len(set(y_pred))\n",
    "        \n",
    "            res[str(trial)] = dict(loss = im.codelength, y_pred = y_pred, ami = ami, m = m)\n",
    "\n",
    "            with open(out, \"w\") as fh:\n",
    "                json.dump(res, fh)\n",
    "\n",
    "    best_result = min(res.values(), key = lambda r: r[\"loss\"])\n",
    "    avg_ami     = np.average([v['ami'] for v in res.values()])\n",
    "    std_ami     = np.std([v['ami'] for v in res.values()])\n",
    "    avg_m       = np.average([v['m'] for v in res.values()])\n",
    "    std_m       = np.std([v['m'] for v in res.values()])\n",
    "    print(f\"[Infomap   ] <AMI> = {100 * avg_ami:4.1f} ± {100 * std_ami:4.1f}, <|M|> = {avg_m:6.1f} ± {std_m:6.1f}, AMI* = {100 * best_result['ami']:4.1f}, |M|* = {best_result['m']:6}\")\n",
    "    \n",
    "    res_str = f\"Infomap,infomap,{100 * avg_ami:.1f},{100 * std_ami:.1f},{avg_m:.1f},{std_m:.1f}\\n\"\n",
    "    \n",
    "    with open(f\"./results/real-world{'-fixed-size-arch' if fixed_size_arch else ''}/{data.name}.csv\", \"a\") as fh:\n",
    "        fh.write(res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "===========================================================================================================\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.9\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root = \"data/Planetoid\", name = \"Cora\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "cora = Data()\n",
    "cora.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "cora.x           = data.x\n",
    "cora.y           = data.y\n",
    "cora.num_classes = dataset.num_classes\n",
    "cora.name        = \"Cora\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(cora, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 31.9 ±  7.9, <|M|> =   14.4 ±    3.7, AMI* = 37.5, |M|* =     20\n",
      "[NOCD      ] <AMI> =  5.1 ±  1.9, <|M|> =   20.5 ±   10.2, AMI* =  4.8, |M|* =     48\n",
      "[DiffPool  ] <AMI> =  0.4 ±  1.1, <|M|> =    2.6 ±    1.1, AMI* =  5.1, |M|* =      6\n",
      "[MinCut    ] <AMI> = 26.1 ±  2.5, <|M|> =   51.3 ±    0.9, AMI* = 28.5, |M|* =     52\n",
      "[Ortho     ] <AMI> =  7.0 ±  0.7, <|M|> =   48.7 ±    1.3, AMI* =  6.5, |M|* =     51\n",
      "[DMoN      ] <AMI> =  1.2 ±  1.6, <|M|> =   13.6 ±   13.3, AMI* =  0.3, |M|* =      7\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 36.6 ±  2.4, <|M|> =   44.4 ±    2.5, AMI* = 37.5, |M|* =     44\n",
      "[NOCD      ] <AMI> = 46.1 ±  1.1, <|M|> =   29.3 ±    2.7, AMI* = 46.1, |M|* =     29\n",
      "[DiffPool  ] <AMI> =  9.0 ±  1.2, <|M|> =   51.8 ±    0.4, AMI* =  9.1, |M|* =     52\n",
      "[MinCut    ] <AMI> = 34.7 ±  6.6, <|M|> =   51.5 ±    1.6, AMI* = 36.4, |M|* =     52\n",
      "[Ortho     ] <AMI> =  5.3 ±  0.5, <|M|> =   52.0 ±    0.0, AMI* =  5.7, |M|* =     52\n",
      "[DMoN      ] <AMI> = 36.6 ±  1.2, <|M|> =   52.0 ±    0.2, AMI* = 38.3, |M|* =     52\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 46.1 ±  2.0, <|M|> =   20.8 ±    2.2, AMI* = 45.8, |M|* =     24\n",
      "[NOCD      ] <AMI> = 43.4 ±  1.1, <|M|> =   24.2 ±    1.7, AMI* = 43.6, |M|* =     27\n",
      "[DiffPool  ] <AMI> = 30.9 ±  3.6, <|M|> =   11.5 ±    2.2, AMI* = 27.9, |M|* =     12\n",
      "[MinCut    ] <AMI> = 39.3 ±  3.8, <|M|> =   21.5 ±   20.0, AMI* = 33.5, |M|* =     52\n",
      "[Ortho     ] <AMI> = 30.7 ±  1.3, <|M|> =   52.0 ±    0.0, AMI* = 32.0, |M|* =     52\n",
      "[DMoN      ] <AMI> = 37.2 ±  1.1, <|M|> =   51.6 ±    0.6, AMI* = 38.3, |M|* =     52\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 38.5 ±  2.0, <|M|> =   50.7 ±    0.9, AMI* = 39.1, |M|* =     50\n",
      "[NOCD      ] <AMI> = 41.1 ±  0.9, <|M|> =   51.7 ±    0.6, AMI* = 42.3, |M|* =     52\n",
      "[DiffPool  ] <AMI> = 39.8 ±  2.0, <|M|> =   48.2 ±    1.6, AMI* = 36.3, |M|* =     51\n",
      "[MinCut    ] <AMI> = 26.2 ±  1.5, <|M|> =   52.0 ±    0.0, AMI* = 27.5, |M|* =     52\n",
      "[Ortho     ] <AMI> = 22.9 ±  0.9, <|M|> =   52.0 ±    0.0, AMI* = 22.9, |M|* =     52\n",
      "[DMoN      ] <AMI> = 38.6 ±  0.9, <|M|> =   51.9 ±    0.3, AMI* = 38.6, |M|* =     52\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 41.6 ±  1.9, <|M|> =   43.9 ±    2.4, AMI* = 41.2, |M|* =     50\n",
      "[NOCD      ] <AMI> = 40.7 ±  0.9, <|M|> =   47.8 ±    1.6, AMI* = 40.2, |M|* =     49\n",
      "[DiffPool  ] <AMI> = 38.3 ±  2.4, <|M|> =   49.7 ±    1.3, AMI* = 36.6, |M|* =     52\n",
      "[MinCut    ] <AMI> = 31.5 ±  1.5, <|M|> =   52.0 ±    0.0, AMI* = 31.9, |M|* =     52\n",
      "[Ortho     ] <AMI> = 18.0 ±  0.9, <|M|> =   52.0 ±    0.0, AMI* = 16.9, |M|* =     52\n",
      "[DMoN      ] <AMI> = 39.1 ±  1.0, <|M|> =   51.8 ±    0.4, AMI* = 38.5, |M|* =     52\n",
      "=====\n",
      "[Infomap   ] <AMI> = 35.2 ±  0.2, <|M|> =  282.2 ±    4.1, AMI* = 35.5, |M|* =    284\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 19.9 ± 10.3, <|M|> =    4.0 ±    1.2, AMI* = 33.9, |M|* =      6\n",
      "[NOCD      ] <AMI> =  2.9 ±  1.3, <|M|> =    7.0 ±    0.0, AMI* =  6.2, |M|* =      7\n",
      "[DiffPool  ] <AMI> =  0.8 ±  1.9, <|M|> =    2.2 ±    0.7, AMI* = -0.0, |M|* =      2\n",
      "[MinCut    ] <AMI> = 30.6 ±  4.3, <|M|> =    7.0 ±    0.0, AMI* = 25.8, |M|* =      7\n",
      "[Ortho     ] <AMI> =  8.2 ±  1.2, <|M|> =    7.0 ±    0.2, AMI* =  8.2, |M|* =      7\n",
      "[DMoN      ] <AMI> = 15.3 ± 11.7, <|M|> =    5.9 ±    1.8, AMI* = 30.8, |M|* =      7\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 32.7 ±  4.6, <|M|> =    7.0 ±    0.0, AMI* = 41.7, |M|* =      7\n",
      "[NOCD      ] <AMI> = 33.1 ± 14.7, <|M|> =    7.0 ±    0.0, AMI* = 42.1, |M|* =      7\n",
      "[DiffPool  ] <AMI> =  4.9 ±  1.3, <|M|> =    7.0 ±    0.0, AMI* =  3.9, |M|* =      7\n",
      "[MinCut    ] <AMI> = 30.4 ±  4.5, <|M|> =    7.0 ±    0.0, AMI* = 40.0, |M|* =      7\n",
      "[Ortho     ] <AMI> =  4.4 ±  1.0, <|M|> =    7.0 ±    0.0, AMI* =  5.4, |M|* =      7\n",
      "[DMoN      ] <AMI> = 36.1 ±  5.2, <|M|> =    6.9 ±    0.3, AMI* = 42.5, |M|* =      7\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 35.8 ±  4.1, <|M|> =    5.5 ±    0.8, AMI* = 39.0, |M|* =      7\n",
      "[NOCD      ] <AMI> = 35.1 ±  4.8, <|M|> =    6.2 ±    0.6, AMI* = 39.8, |M|* =      7\n",
      "[DiffPool  ] <AMI> = 14.0 ±  4.8, <|M|> =    3.7 ±    0.6, AMI* =  2.9, |M|* =      3\n",
      "[MinCut    ] <AMI> = 35.7 ±  2.9, <|M|> =    7.0 ±    0.0, AMI* = 35.5, |M|* =      7\n",
      "[Ortho     ] <AMI> = 19.2 ±  3.6, <|M|> =    7.0 ±    0.0, AMI* = 17.3, |M|* =      7\n",
      "[DMoN      ] <AMI> = 27.4 ±  3.3, <|M|> =    7.0 ±    0.0, AMI* = 27.0, |M|* =      7\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 31.7 ±  3.0, <|M|> =    7.0 ±    0.0, AMI* = 35.3, |M|* =      7\n",
      "[NOCD      ] <AMI> = 32.6 ±  4.6, <|M|> =    7.0 ±    0.0, AMI* = 38.6, |M|* =      7\n",
      "[DiffPool  ] <AMI> = 28.5 ±  4.1, <|M|> =    7.0 ±    0.0, AMI* = 19.8, |M|* =      7\n",
      "[MinCut    ] <AMI> = 31.9 ±  3.7, <|M|> =    7.0 ±    0.0, AMI* = 38.5, |M|* =      7\n",
      "[Ortho     ] <AMI> = 22.0 ±  3.0, <|M|> =    7.0 ±    0.0, AMI* = 20.4, |M|* =      7\n",
      "[DMoN      ] <AMI> = 37.2 ±  4.2, <|M|> =    7.0 ±    0.0, AMI* = 37.8, |M|* =      7\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 32.5 ±  5.0, <|M|> =    7.0 ±    0.0, AMI* = 39.5, |M|* =      7\n",
      "[NOCD      ] <AMI> = 32.5 ±  3.7, <|M|> =    7.0 ±    0.0, AMI* = 38.4, |M|* =      7\n",
      "[DiffPool  ] <AMI> = 24.4 ±  3.0, <|M|> =    7.0 ±    0.0, AMI* = 21.9, |M|* =      7\n",
      "[MinCut    ] <AMI> = 33.6 ±  2.9, <|M|> =    7.0 ±    0.0, AMI* = 39.0, |M|* =      7\n",
      "[Ortho     ] <AMI> = 21.5 ±  4.1, <|M|> =    7.0 ±    0.0, AMI* = 18.8, |M|* =      7\n",
      "[DMoN      ] <AMI> = 37.0 ±  4.0, <|M|> =    7.0 ±    0.2, AMI* = 42.2, |M|* =      7\n",
      "=====\n",
      "[Infomap   ] <AMI> = 35.2 ±  0.2, <|M|> =  282.2 ±    4.1, AMI* = 35.5, |M|* =    284\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = cora, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(cora, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CiteSeer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: CiteSeer():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 3703\n",
      "Number of classes: 6\n",
      "\n",
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
      "===========================================================================================================\n",
      "Number of edges: 9104\n",
      "Average node degree: 2.7\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root = \"data/Planetoid\", name = \"CiteSeer\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "citeseer = Data()\n",
    "citeseer.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "citeseer.x           = data.x\n",
    "citeseer.y           = data.y\n",
    "citeseer.num_classes = dataset.num_classes\n",
    "citeseer.name        = \"CiteSeer\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(citeseer, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 19.5 ±  1.6, <|M|> =   38.0 ±    3.9, AMI* = 21.9, |M|* =     43\n",
      "[NOCD      ] <AMI> =  2.4 ±  1.3, <|M|> =   17.5 ±   21.5, AMI* =  4.5, |M|* =     57\n",
      "[DiffPool  ] <AMI> =  1.1 ±  1.9, <|M|> =    4.6 ±    3.3, AMI* =  2.3, |M|* =     10\n",
      "[MinCut    ] <AMI> = 16.5 ±  1.3, <|M|> =   54.8 ±    1.9, AMI* = 15.2, |M|* =     58\n",
      "[Ortho     ] <AMI> =  5.6 ±  0.7, <|M|> =   53.4 ±    1.7, AMI* =  5.1, |M|* =     57\n",
      "[DMoN      ] <AMI> =  3.2 ±  1.6, <|M|> =   25.1 ±   10.8, AMI* =  3.7, |M|* =     46\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 15.8 ±  1.1, <|M|> =   57.3 ±    0.9, AMI* = 16.8, |M|* =     58\n",
      "[NOCD      ] <AMI> = 34.8 ±  0.9, <|M|> =   23.6 ±    4.1, AMI* = 35.4, |M|* =     22\n",
      "[DiffPool  ] <AMI> =  6.7 ±  1.0, <|M|> =   58.0 ±    0.2, AMI* =  6.3, |M|* =     58\n",
      "[MinCut    ] <AMI> = 20.5 ±  0.9, <|M|> =   58.0 ±    0.0, AMI* = 19.9, |M|* =     58\n",
      "[Ortho     ] <AMI> =  3.8 ±  0.4, <|M|> =   58.0 ±    0.0, AMI* =  4.0, |M|* =     58\n",
      "[DMoN      ] <AMI> = 22.5 ±  0.9, <|M|> =   57.9 ±    0.3, AMI* = 21.7, |M|* =     58\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 23.1 ±  1.2, <|M|> =   32.0 ±    2.7, AMI* = 24.6, |M|* =     36\n",
      "[NOCD      ] <AMI> = 26.4 ±  1.2, <|M|> =   28.8 ±    2.6, AMI* = 28.1, |M|* =     33\n",
      "[DiffPool  ] <AMI> = 21.3 ±  2.3, <|M|> =   17.4 ±    3.1, AMI* = 19.3, |M|* =     23\n",
      "[MinCut    ] <AMI> = 18.9 ±  0.7, <|M|> =   55.7 ±    8.5, AMI* = 18.5, |M|* =     58\n",
      "[Ortho     ] <AMI> = 17.8 ±  0.9, <|M|> =   58.0 ±    0.0, AMI* = 17.1, |M|* =     58\n",
      "[DMoN      ] <AMI> = 19.5 ±  0.9, <|M|> =   57.0 ±    1.0, AMI* = 20.0, |M|* =     57\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 16.2 ±  1.3, <|M|> =   58.0 ±    0.0, AMI* = 15.3, |M|* =     58\n",
      "[NOCD      ] <AMI> = 20.2 ±  0.8, <|M|> =   58.0 ±    0.0, AMI* = 20.5, |M|* =     58\n",
      "[DiffPool  ] <AMI> = 18.2 ±  1.3, <|M|> =   57.9 ±    0.4, AMI* = 15.1, |M|* =     58\n",
      "[MinCut    ] <AMI> = 12.0 ±  0.7, <|M|> =   58.0 ±    0.0, AMI* = 12.8, |M|* =     58\n",
      "[Ortho     ] <AMI> = 10.9 ±  0.7, <|M|> =   58.0 ±    0.0, AMI* = 10.0, |M|* =     58\n",
      "[DMoN      ] <AMI> = 20.4 ±  0.9, <|M|> =   58.0 ±    0.0, AMI* = 21.0, |M|* =     58\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 18.3 ±  1.2, <|M|> =   57.6 ±    0.6, AMI* = 18.1, |M|* =     58\n",
      "[NOCD      ] <AMI> = 19.8 ±  0.8, <|M|> =   56.6 ±    1.3, AMI* = 19.2, |M|* =     56\n",
      "[DiffPool  ] <AMI> = 16.4 ±  1.4, <|M|> =   58.0 ±    0.2, AMI* = 14.3, |M|* =     58\n",
      "[MinCut    ] <AMI> = 16.2 ±  0.8, <|M|> =   58.0 ±    0.0, AMI* = 16.4, |M|* =     58\n",
      "[Ortho     ] <AMI> =  8.4 ±  0.8, <|M|> =   58.0 ±    0.0, AMI* =  8.6, |M|* =     58\n",
      "[DMoN      ] <AMI> = 21.3 ±  1.3, <|M|> =   58.0 ±    0.0, AMI* = 21.2, |M|* =     58\n",
      "=====\n",
      "[Infomap   ] <AMI> = 23.6 ±  0.1, <|M|> =  628.9 ±    2.7, AMI* = 23.6, |M|* =    635\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 12.8 ±  6.9, <|M|> =    4.5 ±    0.9, AMI* = 20.0, |M|* =      5\n",
      "[NOCD      ] <AMI> =  3.0 ±  1.6, <|M|> =    5.8 ±    0.4, AMI* =  4.3, |M|* =      5\n",
      "[DiffPool  ] <AMI> =  1.2 ±  0.5, <|M|> =    3.2 ±    0.6, AMI* =  0.3, |M|* =      2\n",
      "[MinCut    ] <AMI> = 16.7 ±  2.6, <|M|> =    6.0 ±    0.0, AMI* = 18.6, |M|* =      6\n",
      "[Ortho     ] <AMI> =  8.0 ±  2.3, <|M|> =    5.6 ±    0.5, AMI* =  7.6, |M|* =      6\n",
      "[DMoN      ] <AMI> =  9.2 ±  6.9, <|M|> =    5.2 ±    1.5, AMI* = 17.0, |M|* =      6\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 13.6 ±  2.6, <|M|> =    6.0 ±    0.0, AMI* = 19.7, |M|* =      6\n",
      "[NOCD      ] <AMI> = 29.6 ± 10.8, <|M|> =    6.0 ±    0.0, AMI* = 36.7, |M|* =      6\n",
      "[DiffPool  ] <AMI> =  4.1 ±  1.4, <|M|> =    6.0 ±    0.0, AMI* =  3.1, |M|* =      6\n",
      "[MinCut    ] <AMI> = 15.5 ±  3.5, <|M|> =    6.0 ±    0.0, AMI* = 21.6, |M|* =      6\n",
      "[Ortho     ] <AMI> =  3.5 ±  1.0, <|M|> =    6.0 ±    0.0, AMI* =  2.3, |M|* =      6\n",
      "[DMoN      ] <AMI> = 20.2 ±  3.6, <|M|> =    6.0 ±    0.0, AMI* = 23.3, |M|* =      6\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 16.1 ±  3.2, <|M|> =    5.1 ±    0.6, AMI* = 20.6, |M|* =      5\n",
      "[NOCD      ] <AMI> = 19.2 ±  3.4, <|M|> =    5.5 ±    0.6, AMI* = 20.3, |M|* =      6\n",
      "[DiffPool  ] <AMI> =  8.2 ±  3.1, <|M|> =    3.0 ±    0.7, AMI* =  5.3, |M|* =      3\n",
      "[MinCut    ] <AMI> = 18.9 ±  3.0, <|M|> =    6.0 ±    0.0, AMI* = 20.7, |M|* =      6\n",
      "[Ortho     ] <AMI> =  9.4 ±  2.9, <|M|> =    6.0 ±    0.0, AMI* =  8.4, |M|* =      6\n",
      "[DMoN      ] <AMI> = 11.5 ±  3.1, <|M|> =    5.9 ±    0.3, AMI* =  9.0, |M|* =      6\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 12.8 ±  2.9, <|M|> =    6.0 ±    0.0, AMI* = 19.5, |M|* =      6\n",
      "[NOCD      ] <AMI> = 11.7 ±  1.7, <|M|> =    6.0 ±    0.0, AMI* = 14.1, |M|* =      6\n",
      "[DiffPool  ] <AMI> = 12.4 ±  2.5, <|M|> =    6.0 ±    0.0, AMI* = 17.2, |M|* =      6\n",
      "[MinCut    ] <AMI> = 13.1 ±  2.8, <|M|> =    6.0 ±    0.0, AMI* = 20.0, |M|* =      6\n",
      "[Ortho     ] <AMI> = 10.2 ±  2.1, <|M|> =    6.0 ±    0.0, AMI* =  9.7, |M|* =      6\n",
      "[DMoN      ] <AMI> = 18.4 ±  2.6, <|M|> =    6.0 ±    0.0, AMI* = 17.1, |M|* =      6\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 12.9 ±  2.7, <|M|> =    6.0 ±    0.0, AMI* = 18.3, |M|* =      6\n",
      "[NOCD      ] <AMI> = 11.6 ±  2.8, <|M|> =    6.0 ±    0.0, AMI* = 14.5, |M|* =      6\n",
      "[DiffPool  ] <AMI> = 11.6 ±  2.5, <|M|> =    6.0 ±    0.0, AMI* =  7.9, |M|* =      6\n",
      "[MinCut    ] <AMI> = 13.9 ±  3.5, <|M|> =    6.0 ±    0.0, AMI* = 21.5, |M|* =      6\n",
      "[Ortho     ] <AMI> =  7.6 ±  2.5, <|M|> =    6.0 ±    0.0, AMI* =  8.1, |M|* =      6\n",
      "[DMoN      ] <AMI> = 18.0 ±  3.4, <|M|> =    5.9 ±    0.3, AMI* = 16.1, |M|* =      6\n",
      "=====\n",
      "[Infomap   ] <AMI> = 23.6 ±  0.1, <|M|> =  628.9 ±    2.7, AMI* = 23.6, |M|* =    635\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = citeseer, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(citeseer, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PubMed():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "\n",
      "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
      "===========================================================================================================\n",
      "Number of edges: 88648\n",
      "Average node degree: 4.5\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root = \"data/Planetoid\", name = \"PubMed\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "pubmed = Data()\n",
    "pubmed.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "pubmed.x           = data.x\n",
    "pubmed.y           = data.y\n",
    "pubmed.num_classes = dataset.num_classes\n",
    "pubmed.name        = \"PubMed\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(pubmed, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 17.2 ± 12.2, <|M|> =   12.4 ±    8.1, AMI* = 27.7, |M|* =     22\n",
      "[NOCD      ] <AMI> =  3.7 ±  1.7, <|M|> =   12.1 ±    3.1, AMI* =  6.1, |M|* =      8\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> =  2.2 ±  1.0, <|M|> =   40.0 ±    6.1, AMI* =  2.9, |M|* =     50\n",
      "[Ortho     ] <AMI> = 16.5 ±  0.4, <|M|> =   68.1 ±    5.7, AMI* = 16.4, |M|* =     81\n",
      "[DMoN      ] <AMI> =  0.7 ±  1.0, <|M|> =    2.5 ±    1.7, AMI* =  3.4, |M|* =      6\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 23.2 ±  1.8, <|M|> =   30.8 ±    3.8, AMI* = 22.9, |M|* =     34\n",
      "[NOCD      ] <AMI> = 20.5 ±  2.4, <|M|> =   29.8 ±    2.7, AMI* = 22.3, |M|* =     27\n",
      "[DiffPool  ] <AMI> = 18.9 ±  1.4, <|M|> =   43.6 ±    4.7, AMI* = 17.1, |M|* =     44\n",
      "[MinCut    ] <AMI> =  5.1 ±  2.4, <|M|> =   25.7 ±    7.4, AMI* =  8.0, |M|* =     35\n",
      "[Ortho     ] <AMI> = 10.6 ±  0.4, <|M|> =  126.9 ±    4.7, AMI* = 10.9, |M|* =    135\n",
      "[DMoN      ] <AMI> =  6.7 ±  4.1, <|M|> =   24.8 ±   33.0, AMI* = 17.7, |M|* =    139\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 24.6 ±  1.7, <|M|> =   12.7 ±    1.3, AMI* = 24.4, |M|* =     14\n",
      "[NOCD      ] <AMI> = 21.3 ±  0.6, <|M|> =   35.9 ±    6.2, AMI* = 20.8, |M|* =     34\n",
      "[DiffPool  ] <AMI> = 16.3 ±  3.9, <|M|> =    7.3 ±    1.6, AMI* =  9.6, |M|* =      6\n",
      "[MinCut    ] <AMI> = 19.8 ±  4.3, <|M|> =   15.0 ±   37.5, AMI* = 15.6, |M|* =    140\n",
      "[Ortho     ] <AMI> = 13.6 ±  0.5, <|M|> =  140.0 ±    0.0, AMI* = 13.2, |M|* =    140\n",
      "[DMoN      ] <AMI> = 17.0 ±  0.3, <|M|> =  140.0 ±    0.0, AMI* = 17.0, |M|* =    140\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 20.8 ±  1.2, <|M|> =   51.6 ±    4.4, AMI* = 21.2, |M|* =     55\n",
      "[NOCD      ] <AMI> = 21.2 ±  0.6, <|M|> =   35.1 ±    2.9, AMI* = 20.6, |M|* =     37\n",
      "[DiffPool  ] <AMI> = 23.7 ±  1.5, <|M|> =   15.6 ±    2.1, AMI* = 23.0, |M|* =     18\n",
      "[MinCut    ] <AMI> = 11.0 ±  2.8, <|M|> =  134.9 ±    4.1, AMI* = 15.4, |M|* =    140\n",
      "[Ortho     ] <AMI> = 13.8 ±  0.5, <|M|> =  140.0 ±    0.0, AMI* = 13.4, |M|* =    140\n",
      "[DMoN      ] <AMI> = 18.3 ±  0.2, <|M|> =  140.0 ±    0.0, AMI* = 18.4, |M|* =    140\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 20.4 ±  1.0, <|M|> =   34.4 ±    2.5, AMI* = 20.2, |M|* =     40\n",
      "[NOCD      ] <AMI> = 19.6 ±  0.4, <|M|> =   60.6 ±    3.3, AMI* = 19.2, |M|* =     65\n",
      "[DiffPool  ] <AMI> = 21.9 ±  1.5, <|M|> =   26.0 ±    3.0, AMI* = 21.9, |M|* =     24\n",
      "[MinCut    ] <AMI> = 15.5 ±  0.3, <|M|> =  140.0 ±    0.0, AMI* = 15.4, |M|* =    140\n",
      "[Ortho     ] <AMI> =  9.9 ±  0.4, <|M|> =  140.0 ±    0.0, AMI* =  9.2, |M|* =    140\n",
      "[DMoN      ] <AMI> = 17.7 ±  0.2, <|M|> =  140.0 ±    0.2, AMI* = 17.7, |M|* =    140\n",
      "=====\n",
      "[Infomap   ] <AMI> = 16.0 ±  0.1, <|M|> =  924.9 ±    9.1, AMI* = 16.0, |M|* =    929\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  0.9 ±  3.7, <|M|> =    1.1 ±    0.3, AMI* = 18.5, |M|* =      2\n",
      "[NOCD      ] <AMI> =  0.2 ±  0.5, <|M|> =    1.7 ±    0.5, AMI* =  0.6, |M|* =      2\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> = 21.0 ±  1.9, <|M|> =    3.0 ±    0.0, AMI* = 19.7, |M|* =      3\n",
      "[Ortho     ] <AMI> = 15.7 ±  4.6, <|M|> =    2.7 ±    0.4, AMI* = 15.7, |M|* =      3\n",
      "[DMoN      ] <AMI> =  9.1 ±  4.5, <|M|> =    3.0 ±    0.0, AMI* =  7.9, |M|* =      3\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 22.9 ±  4.6, <|M|> =    3.0 ±    0.0, AMI* = 27.4, |M|* =      3\n",
      "[NOCD      ] <AMI> = 16.8 ±  8.1, <|M|> =    3.0 ±    0.0, AMI* = 30.3, |M|* =      3\n",
      "[DiffPool  ] <AMI> = 10.3 ±  3.6, <|M|> =    3.0 ±    0.0, AMI* = 18.1, |M|* =      3\n",
      "[MinCut    ] <AMI> = 19.7 ±  6.3, <|M|> =    3.0 ±    0.0, AMI* = 20.1, |M|* =      3\n",
      "[Ortho     ] <AMI> =  8.5 ±  3.6, <|M|> =    3.0 ±    0.0, AMI* = 16.0, |M|* =      3\n",
      "[DMoN      ] <AMI> = 19.0 ±  6.5, <|M|> =    3.0 ±    0.0, AMI* = 18.2, |M|* =      3\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 16.1 ±  5.8, <|M|> =    2.8 ±    0.4, AMI* = 27.6, |M|* =      3\n",
      "[NOCD      ] <AMI> = 17.0 ±  6.3, <|M|> =    2.9 ±    0.3, AMI* = 22.3, |M|* =      3\n",
      "[DiffPool  ] <AMI> =  2.1 ±  1.7, <|M|> =    2.2 ±    0.4, AMI* =  1.1, |M|* =      2\n",
      "[MinCut    ] <AMI> = 20.2 ±  4.1, <|M|> =    3.0 ±    0.0, AMI* = 22.8, |M|* =      3\n",
      "[Ortho     ] <AMI> =  6.3 ±  3.0, <|M|> =    3.0 ±    0.0, AMI* =  6.4, |M|* =      3\n",
      "[DMoN      ] <AMI> = 10.3 ±  7.1, <|M|> =    3.0 ±    0.0, AMI* = 32.4, |M|* =      3\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 19.2 ±  5.8, <|M|> =    3.0 ±    0.0, AMI* = 32.3, |M|* =      3\n",
      "[NOCD      ] <AMI> = 19.3 ±  7.3, <|M|> =    3.0 ±    0.0, AMI* = 26.8, |M|* =      3\n",
      "[DiffPool  ] <AMI> = 18.8 ±  5.5, <|M|> =    3.0 ±    0.0, AMI* = 24.7, |M|* =      3\n",
      "[MinCut    ] <AMI> = 18.5 ±  4.2, <|M|> =    3.0 ±    0.0, AMI* = 18.0, |M|* =      3\n",
      "[Ortho     ] <AMI> = 16.4 ±  4.8, <|M|> =    3.0 ±    0.0, AMI* = 23.0, |M|* =      3\n",
      "[DMoN      ] <AMI> = 19.3 ±  4.0, <|M|> =    3.0 ±    0.0, AMI* = 25.6, |M|* =      3\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 19.8 ±  4.6, <|M|> =    3.0 ±    0.0, AMI* = 25.4, |M|* =      3\n",
      "[NOCD      ] <AMI> = 22.6 ±  4.9, <|M|> =    3.0 ±    0.0, AMI* = 25.3, |M|* =      3\n",
      "[DiffPool  ] <AMI> = 18.9 ±  5.0, <|M|> =    3.0 ±    0.0, AMI* = 21.0, |M|* =      3\n",
      "[MinCut    ] <AMI> = 17.1 ±  3.7, <|M|> =    3.0 ±    0.0, AMI* = 17.1, |M|* =      3\n",
      "[Ortho     ] <AMI> = 15.9 ±  3.8, <|M|> =    3.0 ±    0.0, AMI* = 14.9, |M|* =      3\n",
      "[DMoN      ] <AMI> = 17.5 ±  3.7, <|M|> =    3.0 ±    0.0, AMI* = 23.2, |M|* =      3\n",
      "=====\n",
      "[Infomap   ] <AMI> = 16.0 ±  0.1, <|M|> =  924.9 ±    9.1, AMI* = 16.0, |M|* =    929\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = pubmed, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(pubmed, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Computer (PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: AmazonComputers():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 767\n",
      "Number of classes: 10\n",
      "\n",
      "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752])\n",
      "===========================================================================================================\n",
      "Number of edges: 491722\n",
      "Average node degree: 35.8\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.22\n"
     ]
    }
   ],
   "source": [
    "dataset = Amazon(root = \"data/Amazon\", name = \"Computers\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "pc = Data()\n",
    "pc.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "pc.x           = data.x\n",
    "pc.y           = data.y\n",
    "pc.num_classes = dataset.num_classes\n",
    "pc.name        = \"PC\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(pc, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[NOCD      ] <AMI> =  1.2 ±  2.7, <|M|> =    1.7 ±    1.0, AMI* =  8.9, |M|* =      3\n",
      "[DiffPool  ] <AMI> = -0.0 ±  0.0, <|M|> =    1.2 ±    0.5, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> = -0.0 ±  0.0, <|M|> =    1.0 ±    0.2, AMI* =  0.0, |M|* =      1\n",
      "[Ortho     ] <AMI> = 18.8 ±  9.0, <|M|> =    9.5 ±    4.1, AMI* = 25.7, |M|* =     16\n",
      "[DMoN      ] <AMI> =  3.4 ±  2.9, <|M|> =    2.4 ±    1.0, AMI* =  9.9, |M|* =      4\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 22.4 ±  8.6, <|M|> =    3.0 ±    0.8, AMI* = 40.3, |M|* =      4\n",
      "[NOCD      ] <AMI> = 45.5 ±  2.5, <|M|> =   13.9 ±    3.9, AMI* = 48.8, |M|* =     12\n",
      "[DiffPool  ] <AMI> =  1.6 ±  0.4, <|M|> =    2.2 ±    0.5, AMI* =  1.6, |M|* =      3\n",
      "[MinCut    ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[Ortho     ] <AMI> = 19.8 ±  5.5, <|M|> =    8.8 ±    2.3, AMI* = 26.4, |M|* =     14\n",
      "[DMoN      ] <AMI> = 15.4 ± 11.6, <|M|> =   51.4 ±   36.3, AMI* = 29.7, |M|* =     94\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 43.2 ±  2.4, <|M|> =    6.4 ±    1.3, AMI* = 46.6, |M|* =      8\n",
      "[NOCD      ] <AMI> = 34.2 ±  1.9, <|M|> =   33.1 ±    5.8, AMI* = 34.6, |M|* =     35\n",
      "[DiffPool  ] <AMI> = 14.5 ±  3.2, <|M|> =    3.5 ±    0.6, AMI* = 11.6, |M|* =      3\n",
      "[MinCut    ] <AMI> =  6.8 ±  6.8, <|M|> =   11.0 ±    4.2, AMI* = 23.9, |M|* =      2\n",
      "[Ortho     ] <AMI> = 34.0 ±  0.9, <|M|> =   95.8 ±    4.4, AMI* = 33.1, |M|* =    103\n",
      "[DMoN      ] <AMI> = 35.4 ±  2.3, <|M|> =  110.6 ±    6.1, AMI* = 38.1, |M|* =    116\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 52.1 ±  2.3, <|M|> =   21.2 ±    3.4, AMI* = 51.4, |M|* =     25\n",
      "[NOCD      ] <AMI> = 51.9 ±  1.9, <|M|> =   72.3 ±   19.2, AMI* = 53.0, |M|* =     41\n",
      "[DiffPool  ] <AMI> = 37.0 ±  8.0, <|M|> =    5.7 ±    1.1, AMI* = 29.6, |M|* =      6\n",
      "[MinCut    ] <AMI> = 15.9 ± 21.2, <|M|> =   69.5 ±   25.2, AMI* = 40.5, |M|* =    116\n",
      "[Ortho     ] <AMI> = 40.7 ±  0.9, <|M|> =  114.9 ±    1.6, AMI* = 40.4, |M|* =    117\n",
      "[DMoN      ] <AMI> = 43.8 ±  0.3, <|M|> =  117.0 ±    0.0, AMI* = 44.1, |M|* =    117\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 43.6 ±  4.8, <|M|> =    7.2 ±    1.9, AMI* = 54.2, |M|* =     11\n",
      "[NOCD      ] <AMI> = 51.1 ±  1.6, <|M|> =   32.0 ±    3.0, AMI* = 53.1, |M|* =     31\n",
      "[DiffPool  ] <AMI> =  3.1 ±  0.3, <|M|> =    3.2 ±    0.4, AMI* =  4.6, |M|* =      4\n",
      "[MinCut    ] <AMI> = 41.6 ±  0.6, <|M|> =  115.9 ±    2.8, AMI* = 42.2, |M|* =    117\n",
      "[Ortho     ] <AMI> = 35.4 ±  3.9, <|M|> =   52.5 ±   30.2, AMI* = 37.3, |M|* =    110\n",
      "[DMoN      ] <AMI> = 37.4 ± 11.9, <|M|> =  116.8 ±    0.7, AMI* = 43.5, |M|* =    117\n",
      "=====\n",
      "[Infomap   ] <AMI> = 49.5 ±  0.5, <|M|> =  455.1 ±    5.1, AMI* = 50.0, |M|* =    459\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = -0.0 ±  0.0, <|M|> =    1.0 ±    0.2, AMI* =  0.0, |M|* =      1\n",
      "[NOCD      ] <AMI> =  1.9 ±  2.5, <|M|> =    3.2 ±    1.1, AMI* =  1.3, |M|* =      4\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> =  3.1 ±  8.5, <|M|> =    1.3 ±    0.7, AMI* = 33.6, |M|* =      4\n",
      "[Ortho     ] <AMI> = 12.4 ±  6.5, <|M|> =    4.5 ±    1.5, AMI* = 20.0, |M|* =      7\n",
      "[DMoN      ] <AMI> =  1.0 ±  0.8, <|M|> =    2.2 ±    0.9, AMI* =  1.0, |M|* =      3\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 33.6 ± 13.3, <|M|> =    3.7 ±    0.9, AMI* = 46.8, |M|* =      4\n",
      "[NOCD      ] <AMI> = 47.9 ±  2.1, <|M|> =    9.4 ±    0.9, AMI* = 50.5, |M|* =     10\n",
      "[DiffPool  ] <AMI> =  1.6 ±  0.4, <|M|> =    2.2 ±    0.4, AMI* =  2.5, |M|* =      3\n",
      "[MinCut    ] <AMI> = 38.8 ± 13.3, <|M|> =    7.7 ±    3.4, AMI* = 48.7, |M|* =     10\n",
      "[Ortho     ] <AMI> = 22.4 ±  5.7, <|M|> =    8.3 ±    1.5, AMI* = 30.5, |M|* =     10\n",
      "[DMoN      ] <AMI> = 45.0 ±  2.2, <|M|> =   10.0 ±    0.0, AMI* = 46.8, |M|* =     10\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 40.5 ±  3.9, <|M|> =    3.6 ±    0.5, AMI* = 40.7, |M|* =      4\n",
      "[NOCD      ] <AMI> = 32.6 ±  3.7, <|M|> =    8.5 ±    0.6, AMI* = 34.8, |M|* =      8\n",
      "[DiffPool  ] <AMI> =  5.3 ±  5.6, <|M|> =    4.6 ±    1.2, AMI* = 13.2, |M|* =      3\n",
      "[MinCut    ] <AMI> = 32.4 ±  7.8, <|M|> =    6.1 ±    1.8, AMI* = 43.1, |M|* =     10\n",
      "[Ortho     ] <AMI> = 37.4 ±  3.8, <|M|> =   10.0 ±    0.0, AMI* = 38.4, |M|* =     10\n",
      "[DMoN      ] <AMI> = 35.3 ±  2.3, <|M|> =    9.9 ±    0.3, AMI* = 39.9, |M|* =     10\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 49.9 ±  3.6, <|M|> =    9.7 ±    0.5, AMI* = 52.2, |M|* =      9\n",
      "[NOCD      ] <AMI> = 49.6 ±  2.2, <|M|> =   10.0 ±    0.0, AMI* = 45.5, |M|* =     10\n",
      "[DiffPool  ] <AMI> = 30.4 ±  9.1, <|M|> =    5.3 ±    1.4, AMI* = 38.8, |M|* =      4\n",
      "[MinCut    ] <AMI> = 46.3 ±  2.0, <|M|> =   10.0 ±    0.0, AMI* = 48.3, |M|* =     10\n",
      "[Ortho     ] <AMI> = 45.1 ±  1.9, <|M|> =   10.0 ±    0.0, AMI* = 48.4, |M|* =     10\n",
      "[DMoN      ] <AMI> = 46.4 ±  1.9, <|M|> =   10.0 ±    0.0, AMI* = 47.1, |M|* =     10\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 45.5 ±  5.4, <|M|> =    6.5 ±    0.9, AMI* = 48.4, |M|* =      6\n",
      "[NOCD      ] <AMI> = 47.7 ±  2.4, <|M|> =   10.0 ±    0.2, AMI* = 47.5, |M|* =     10\n",
      "[DiffPool  ] <AMI> =  3.1 ±  0.6, <|M|> =    3.2 ±    0.4, AMI* =  3.9, |M|* =      4\n",
      "[MinCut    ] <AMI> = 43.7 ±  2.5, <|M|> =   10.0 ±    0.0, AMI* = 46.6, |M|* =     10\n",
      "[Ortho     ] <AMI> = 29.4 ±  2.3, <|M|> =   10.0 ±    0.0, AMI* = 31.2, |M|* =     10\n",
      "[DMoN      ] <AMI> = 46.4 ±  1.6, <|M|> =   10.0 ±    0.0, AMI* = 48.9, |M|* =     10\n",
      "=====\n",
      "[Infomap   ] <AMI> = 49.5 ±  0.5, <|M|> =  455.1 ±    5.1, AMI* = 50.0, |M|* =    459\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = pc, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(pc, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_photo.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: AmazonPhoto():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 745\n",
      "Number of classes: 8\n",
      "\n",
      "Data(x=[7650, 745], edge_index=[2, 238162], y=[7650])\n",
      "===========================================================================================================\n",
      "Number of edges: 238162\n",
      "Average node degree: 31.1\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.17\n"
     ]
    }
   ],
   "source": [
    "dataset = Amazon(root = \"data/Amazon\", name = \"Photo\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "photo = Data()\n",
    "photo.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "photo.x           = data.x\n",
    "photo.y           = data.y\n",
    "photo.num_classes = dataset.num_classes\n",
    "photo.name        = \"Photo\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(photo, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[NOCD      ] <AMI> =  0.1 ±  0.3, <|M|> =    1.0 ±    0.2, AMI* =  1.5, |M|* =      2\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> =  0.0 ±  0.0, <|M|> =    1.1 ±    0.3, AMI* =  0.0, |M|* =      1\n",
      "[Ortho     ] <AMI> = 24.7 ± 11.4, <|M|> =    9.4 ±    5.1, AMI* = 32.9, |M|* =     19\n",
      "[DMoN      ] <AMI> =  3.7 ±  4.0, <|M|> =    2.6 ±    1.4, AMI* =  1.7, |M|* =      5\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 39.8 ± 11.2, <|M|> =    4.0 ±    1.2, AMI* = 59.8, |M|* =      7\n",
      "[NOCD      ] <AMI> = 60.5 ±  3.4, <|M|> =   11.0 ±    2.5, AMI* = 67.6, |M|* =     10\n",
      "[DiffPool  ] <AMI> =  3.1 ±  0.9, <|M|> =    2.2 ±    0.4, AMI* =  2.8, |M|* =      3\n",
      "[MinCut    ] <AMI> =  5.2 ±  9.9, <|M|> =    1.2 ±    0.4, AMI* = 30.6, |M|* =      2\n",
      "[Ortho     ] <AMI> = 30.6 ±  4.0, <|M|> =   11.2 ±    2.0, AMI* = 38.4, |M|* =     17\n",
      "[DMoN      ] <AMI> = 43.5 ±  8.9, <|M|> =   81.2 ±   15.0, AMI* = 47.1, |M|* =     87\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 58.2 ±  6.0, <|M|> =    6.8 ±    0.8, AMI* = 62.4, |M|* =      8\n",
      "[NOCD      ] <AMI> = 55.3 ±  1.9, <|M|> =   25.1 ±    4.0, AMI* = 56.4, |M|* =     23\n",
      "[DiffPool  ] <AMI> = 32.8 ±  4.6, <|M|> =    5.2 ±    0.8, AMI* = 31.1, |M|* =      4\n",
      "[MinCut    ] <AMI> = 35.5 ± 19.3, <|M|> =   10.1 ±    5.5, AMI* = 51.6, |M|* =     23\n",
      "[Ortho     ] <AMI> = 42.3 ±  0.7, <|M|> =   78.8 ±    2.8, AMI* = 41.8, |M|* =     83\n",
      "[DMoN      ] <AMI> = 45.6 ±  0.8, <|M|> =   84.5 ±    1.7, AMI* = 46.2, |M|* =     87\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 65.0 ±  3.8, <|M|> =   19.6 ±    2.1, AMI* = 69.5, |M|* =     19\n",
      "[NOCD      ] <AMI> = 63.2 ±  0.9, <|M|> =   51.1 ±   11.0, AMI* = 64.2, |M|* =     25\n",
      "[DiffPool  ] <AMI> = 53.8 ±  7.5, <|M|> =    5.7 ±    0.8, AMI* = 55.8, |M|* =      5\n",
      "[MinCut    ] <AMI> = 45.2 ± 13.6, <|M|> =   62.8 ±   20.3, AMI* = 46.4, |M|* =     86\n",
      "[Ortho     ] <AMI> = 46.0 ±  1.4, <|M|> =   85.0 ±    3.3, AMI* = 45.7, |M|* =     87\n",
      "[DMoN      ] <AMI> = 50.5 ±  0.3, <|M|> =   87.0 ±    0.0, AMI* = 50.7, |M|* =     87\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 48.1 ±  5.8, <|M|> =    8.1 ±    1.3, AMI* = 58.6, |M|* =     10\n",
      "[NOCD      ] <AMI> = 63.7 ±  1.6, <|M|> =   25.1 ±    3.0, AMI* = 62.2, |M|* =     30\n",
      "[DiffPool  ] <AMI> = 16.7 ±  6.1, <|M|> =    3.9 ±    0.7, AMI* = 22.0, |M|* =      4\n",
      "[MinCut    ] <AMI> = 46.9 ±  0.5, <|M|> =   86.9 ±    0.3, AMI* = 47.1, |M|* =     87\n",
      "[Ortho     ] <AMI> = 46.3 ±  1.6, <|M|> =   52.4 ±   21.7, AMI* = 43.1, |M|* =     84\n",
      "[DMoN      ] <AMI> = 50.8 ±  0.3, <|M|> =   86.8 ±    0.4, AMI* = 50.6, |M|* =     87\n",
      "=====\n",
      "[Infomap   ] <AMI> = 57.3 ±  1.1, <|M|> =  223.5 ±    4.4, AMI* = 57.5, |M|* =    222\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[NOCD      ] <AMI> =  2.1 ±  3.0, <|M|> =    2.8 ±    1.2, AMI* =  0.0, |M|* =      3\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> =  1.9 ±  6.4, <|M|> =    1.1 ±    0.3, AMI* = 23.3, |M|* =      2\n",
      "[Ortho     ] <AMI> = 13.6 ±  8.6, <|M|> =    3.8 ±    1.4, AMI* = 25.8, |M|* =      6\n",
      "[DMoN      ] <AMI> =  2.0 ±  2.1, <|M|> =    2.3 ±    1.0, AMI* =  0.0, |M|* =      1\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 51.3 ± 11.1, <|M|> =    4.1 ±    1.1, AMI* = 70.0, |M|* =      6\n",
      "[NOCD      ] <AMI> = 55.1 ± 15.4, <|M|> =    7.4 ±    0.6, AMI* = 68.3, |M|* =      8\n",
      "[DiffPool  ] <AMI> =  3.5 ±  1.4, <|M|> =    2.6 ±    0.7, AMI* =  8.9, |M|* =      4\n",
      "[MinCut    ] <AMI> = 56.4 ±  2.7, <|M|> =    8.0 ±    0.0, AMI* = 58.0, |M|* =      8\n",
      "[Ortho     ] <AMI> = 27.1 ±  2.9, <|M|> =    7.4 ±    0.7, AMI* = 29.6, |M|* =      8\n",
      "[DMoN      ] <AMI> = 56.7 ±  3.1, <|M|> =    8.0 ±    0.0, AMI* = 57.7, |M|* =      8\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 50.3 ±  7.0, <|M|> =    4.8 ±    0.9, AMI* = 56.4, |M|* =      6\n",
      "[NOCD      ] <AMI> = 43.3 ±  4.1, <|M|> =    6.8 ±    1.0, AMI* = 45.6, |M|* =      8\n",
      "[DiffPool  ] <AMI> =  5.7 ±  6.8, <|M|> =    4.3 ±    1.1, AMI* =  0.4, |M|* =      4\n",
      "[MinCut    ] <AMI> = 49.2 ±  4.9, <|M|> =    7.9 ±    0.3, AMI* = 56.0, |M|* =      8\n",
      "[Ortho     ] <AMI> = 45.9 ±  3.0, <|M|> =    8.0 ±    0.0, AMI* = 44.6, |M|* =      8\n",
      "[DMoN      ] <AMI> = 42.6 ±  4.9, <|M|> =    8.0 ±    0.0, AMI* = 46.5, |M|* =      8\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 61.4 ±  4.2, <|M|> =    8.0 ±    0.2, AMI* = 69.8, |M|* =      8\n",
      "[NOCD      ] <AMI> = 64.4 ±  4.1, <|M|> =    8.0 ±    0.0, AMI* = 67.4, |M|* =      8\n",
      "[DiffPool  ] <AMI> = 46.4 ±  6.5, <|M|> =    5.0 ±    0.7, AMI* = 53.1, |M|* =      5\n",
      "[MinCut    ] <AMI> = 56.1 ±  2.9, <|M|> =    8.0 ±    0.0, AMI* = 59.0, |M|* =      8\n",
      "[Ortho     ] <AMI> = 54.4 ±  3.6, <|M|> =    8.0 ±    0.0, AMI* = 53.2, |M|* =      8\n",
      "[DMoN      ] <AMI> = 57.7 ±  2.8, <|M|> =    8.0 ±    0.0, AMI* = 65.7, |M|* =      8\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 49.2 ±  6.1, <|M|> =    6.1 ±    0.5, AMI* = 55.8, |M|* =      7\n",
      "[NOCD      ] <AMI> = 63.3 ±  3.5, <|M|> =    8.0 ±    0.0, AMI* = 66.0, |M|* =      8\n",
      "[DiffPool  ] <AMI> = 12.8 ±  6.1, <|M|> =    3.3 ±    0.5, AMI* = 22.0, |M|* =      4\n",
      "[MinCut    ] <AMI> = 54.0 ±  2.8, <|M|> =    8.0 ±    0.0, AMI* = 52.8, |M|* =      8\n",
      "[Ortho     ] <AMI> = 36.6 ±  3.2, <|M|> =    8.0 ±    0.0, AMI* = 37.7, |M|* =      8\n",
      "[DMoN      ] <AMI> = 58.0 ±  3.2, <|M|> =    8.0 ±    0.0, AMI* = 57.0, |M|* =      8\n",
      "=====\n",
      "[Infomap   ] <AMI> = 57.3 ±  1.1, <|M|> =  223.5 ±    4.4, AMI* = 57.5, |M|* =    222\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = photo, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(photo, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coauthor CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/ms_academic_cs.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: CoauthorCS():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 6805\n",
      "Number of classes: 15\n",
      "\n",
      "Data(x=[18333, 6805], edge_index=[2, 163788], y=[18333])\n",
      "===========================================================================================================\n",
      "Number of edges: 163788\n",
      "Average node degree: 8.9\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.19\n"
     ]
    }
   ],
   "source": [
    "dataset = Coauthor(root = \"data/Coauthor\", name = \"CS\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "cs = Data()\n",
    "cs.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "cs.x           = data.x\n",
    "cs.y           = data.y\n",
    "cs.num_classes = dataset.num_classes\n",
    "cs.name        = \"CS\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(cs, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 76.7 ±  1.4, <|M|> =   50.1 ±    5.2, AMI* = 75.9, |M|* =     54\n",
      "[NOCD      ] <AMI> = 40.2 ±  9.8, <|M|> =   34.7 ±    8.5, AMI* = 51.0, |M|* =     39\n",
      "[DiffPool  ] <AMI> = 22.2 ± 14.3, <|M|> =    6.7 ±    6.1, AMI* = 43.4, |M|* =     16\n",
      "[MinCut    ] <AMI> = 57.5 ±  0.6, <|M|> =   91.0 ±    3.9, AMI* = 57.4, |M|* =    101\n",
      "[Ortho     ] <AMI> = 45.4 ±  2.0, <|M|> =   97.4 ±    6.6, AMI* = 41.6, |M|* =    111\n",
      "[DMoN      ] <AMI> = 25.2 ± 10.8, <|M|> =   10.0 ±    6.3, AMI* = 25.8, |M|* =     31\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 78.1 ±  2.0, <|M|> =   22.2 ±    2.4, AMI* = 81.1, |M|* =     24\n",
      "[NOCD      ] <AMI> = 73.9 ±  1.7, <|M|> =   20.4 ±    3.7, AMI* = 72.2, |M|* =     24\n",
      "[DiffPool  ] <AMI> = 64.5 ±  4.8, <|M|> =   16.5 ±    2.6, AMI* = 66.5, |M|* =     21\n",
      "[MinCut    ] <AMI> = 53.9 ±  6.4, <|M|> =   21.2 ±   41.8, AMI* = 44.3, |M|* =    135\n",
      "[Ortho     ] <AMI> = 56.3 ±  1.7, <|M|> =   48.1 ±    9.1, AMI* = 52.7, |M|* =     68\n",
      "[DMoN      ] <AMI> = 40.2 ±  6.5, <|M|> =   63.1 ±   17.1, AMI* = 57.4, |M|* =    119\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 69.1 ±  2.8, <|M|> =   14.2 ±    2.6, AMI* = 68.9, |M|* =     15\n",
      "[NOCD      ] <AMI> = 63.7 ±  0.9, <|M|> =   27.0 ±    4.1, AMI* = 63.9, |M|* =     23\n",
      "[DiffPool  ] <AMI> = 50.3 ±  3.9, <|M|> =    7.0 ±    1.1, AMI* = 55.7, |M|* =      7\n",
      "[MinCut    ] <AMI> = 32.7 ± 19.5, <|M|> =   73.9 ±   63.8, AMI* = 44.6, |M|* =    135\n",
      "[Ortho     ] <AMI> = 44.1 ±  0.6, <|M|> =  135.0 ±    0.0, AMI* = 43.4, |M|* =    135\n",
      "[DMoN      ] <AMI> = 49.9 ±  0.4, <|M|> =  134.9 ±    0.3, AMI* = 50.1, |M|* =    135\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 70.4 ±  1.6, <|M|> =   34.6 ±    4.5, AMI* = 70.3, |M|* =     42\n",
      "[NOCD      ] <AMI> = 63.3 ±  1.0, <|M|> =   68.4 ±    8.6, AMI* = 62.3, |M|* =     64\n",
      "[DiffPool  ] <AMI> = 73.3 ±  2.0, <|M|> =   12.8 ±    2.3, AMI* = 73.3, |M|* =     18\n",
      "[MinCut    ] <AMI> = 44.7 ±  3.3, <|M|> =  133.2 ±    2.9, AMI* = 46.2, |M|* =    135\n",
      "[Ortho     ] <AMI> = 51.6 ±  1.0, <|M|> =  115.6 ±   11.9, AMI* = 49.8, |M|* =    135\n",
      "[DMoN      ] <AMI> = 53.1 ±  0.2, <|M|> =  135.0 ±    0.0, AMI* = 53.0, |M|* =    135\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 70.9 ±  2.4, <|M|> =   22.0 ±    2.8, AMI* = 75.7, |M|* =     24\n",
      "[NOCD      ] <AMI> = 63.7 ±  0.8, <|M|> =   45.3 ±    3.6, AMI* = 62.4, |M|* =     53\n",
      "[DiffPool  ] <AMI> = 71.4 ±  3.4, <|M|> =   10.7 ±    1.6, AMI* = 74.1, |M|* =     14\n",
      "[MinCut    ] <AMI> = 47.1 ±  0.5, <|M|> =  135.0 ±    0.0, AMI* = 47.3, |M|* =    135\n",
      "[Ortho     ] <AMI> = 52.8 ±  1.2, <|M|> =   84.9 ±   17.5, AMI* = 50.9, |M|* =    119\n",
      "[DMoN      ] <AMI> = 53.1 ±  0.3, <|M|> =  135.0 ±    0.0, AMI* = 52.3, |M|* =    135\n",
      "=====\n",
      "[Infomap   ] <AMI> = 40.6 ±  0.2, <|M|> =  834.4 ±    9.4, AMI* = 40.7, |M|* =    836\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 71.9 ±  3.7, <|M|> =   10.6 ±    1.4, AMI* = 77.3, |M|* =     12\n",
      "[NOCD      ] <AMI> = 24.5 ±  7.7, <|M|> =   10.8 ±    2.5, AMI* = 36.4, |M|* =     12\n",
      "[DiffPool  ] <AMI> = 20.0 ± 14.2, <|M|> =    6.9 ±    2.5, AMI* = 32.7, |M|* =     11\n",
      "[MinCut    ] <AMI> = 68.9 ±  3.0, <|M|> =   13.8 ±    1.1, AMI* = 68.3, |M|* =     15\n",
      "[Ortho     ] <AMI> = 57.4 ±  2.6, <|M|> =   13.3 ±    0.6, AMI* = 59.8, |M|* =     14\n",
      "[DMoN      ] <AMI> = 55.1 ± 12.9, <|M|> =   14.1 ±    2.5, AMI* = 57.6, |M|* =     15\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 74.8 ±  2.4, <|M|> =   12.2 ±    1.2, AMI* = 75.5, |M|* =     14\n",
      "[NOCD      ] <AMI> = 74.0 ±  1.4, <|M|> =   13.5 ±    1.1, AMI* = 74.4, |M|* =     14\n",
      "[DiffPool  ] <AMI> = 50.6 ±  6.7, <|M|> =   11.6 ±    1.9, AMI* = 57.1, |M|* =     13\n",
      "[MinCut    ] <AMI> = 66.5 ±  1.2, <|M|> =   15.0 ±    0.0, AMI* = 65.7, |M|* =     15\n",
      "[Ortho     ] <AMI> = 55.8 ±  2.7, <|M|> =   15.0 ±    0.0, AMI* = 59.1, |M|* =     15\n",
      "[DMoN      ] <AMI> = 72.1 ±  1.1, <|M|> =   15.0 ±    0.0, AMI* = 72.4, |M|* =     15\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 65.2 ±  3.4, <|M|> =    7.9 ±    0.8, AMI* = 66.9, |M|* =      9\n",
      "[NOCD      ] <AMI> = 60.0 ±  3.8, <|M|> =   12.7 ±    1.4, AMI* = 62.7, |M|* =     12\n",
      "[DiffPool  ] <AMI> = 28.4 ±  9.1, <|M|> =    6.2 ±    3.1, AMI* = 20.5, |M|* =      4\n",
      "[MinCut    ] <AMI> = 60.7 ±  1.4, <|M|> =   15.0 ±    0.0, AMI* = 61.5, |M|* =     15\n",
      "[Ortho     ] <AMI> = 51.8 ±  2.7, <|M|> =   15.0 ±    0.0, AMI* = 50.2, |M|* =     15\n",
      "[DMoN      ] <AMI> = 53.1 ±  3.7, <|M|> =   15.0 ±    0.0, AMI* = 55.5, |M|* =     15\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 68.4 ±  2.4, <|M|> =   13.8 ±    1.0, AMI* = 71.1, |M|* =     15\n",
      "[NOCD      ] <AMI> = 68.0 ±  2.3, <|M|> =   15.0 ±    0.0, AMI* = 70.0, |M|* =     15\n",
      "[DiffPool  ] <AMI> = 69.0 ±  3.9, <|M|> =   10.0 ±    1.2, AMI* = 75.2, |M|* =     12\n",
      "[MinCut    ] <AMI> = 62.1 ±  1.4, <|M|> =   15.0 ±    0.0, AMI* = 60.9, |M|* =     15\n",
      "[Ortho     ] <AMI> = 62.2 ±  2.0, <|M|> =   15.0 ±    0.0, AMI* = 66.5, |M|* =     15\n",
      "[DMoN      ] <AMI> = 66.6 ±  1.9, <|M|> =   15.0 ±    0.0, AMI* = 67.4, |M|* =     15\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 69.0 ±  2.8, <|M|> =   12.7 ±    1.2, AMI* = 71.0, |M|* =     15\n",
      "[NOCD      ] <AMI> = 69.7 ±  1.9, <|M|> =   15.0 ±    0.0, AMI* = 68.9, |M|* =     15\n",
      "[DiffPool  ] <AMI> = 65.6 ±  4.5, <|M|> =    8.4 ±    1.3, AMI* = 75.8, |M|* =     11\n",
      "[MinCut    ] <AMI> = 62.3 ±  1.2, <|M|> =   15.0 ±    0.0, AMI* = 64.2, |M|* =     15\n",
      "[Ortho     ] <AMI> = 60.9 ±  2.1, <|M|> =   15.0 ±    0.0, AMI* = 59.1, |M|* =     15\n",
      "[DMoN      ] <AMI> = 66.3 ±  1.6, <|M|> =   15.0 ±    0.0, AMI* = 68.1, |M|* =     15\n",
      "=====\n",
      "[Infomap   ] <AMI> = 40.6 ±  0.2, <|M|> =  834.4 ±    9.4, AMI* = 40.7, |M|* =    836\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = cs, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(cs, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coauthor Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/ms_academic_phy.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: CoauthorPhysics():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 8415\n",
      "Number of classes: 5\n",
      "\n",
      "Data(x=[34493, 8415], edge_index=[2, 495924], y=[34493])\n",
      "===========================================================================================================\n",
      "Number of edges: 495924\n",
      "Average node degree: 14.4\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Mixing µ = 0.07\n"
     ]
    }
   ],
   "source": [
    "dataset = Coauthor(root = \"data/Coauthor\", name=\"Physics\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "physics = Data()\n",
    "physics.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "physics.x           = data.x\n",
    "physics.y           = data.y\n",
    "physics.num_classes = dataset.num_classes\n",
    "physics.name        = \"Physics\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(physics, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 56.5 ±  1.2, <|M|> =   34.5 ±    4.5, AMI* = 56.4, |M|* =     36\n",
      "[NOCD      ] <AMI> = 19.3 ±  7.0, <|M|> =   21.6 ±    2.4, AMI* = 13.3, |M|* =     25\n",
      "[DiffPool  ] <AMI> = 18.9 ± 15.9, <|M|> =    8.1 ±    5.5, AMI* = 35.7, |M|* =     16\n",
      "[MinCut    ] <AMI> = 36.8 ±  0.9, <|M|> =   89.6 ±    6.2, AMI* = 35.4, |M|* =    101\n",
      "[Ortho     ] <AMI> = 26.7 ±  1.5, <|M|> =  149.5 ±    5.4, AMI* = 24.6, |M|* =    161\n",
      "[DMoN      ] <AMI> =  5.7 ±  7.3, <|M|> =    7.7 ±    6.7, AMI* =  9.5, |M|* =     13\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 55.9 ±  2.2, <|M|> =   35.8 ±    3.3, AMI* = 55.5, |M|* =     40\n",
      "[NOCD      ] <AMI> = 50.2 ±  1.0, <|M|> =   22.8 ±    2.7, AMI* = 48.8, |M|* =     27\n",
      "[DiffPool  ] <AMI> = 49.1 ±  4.4, <|M|> =   39.8 ±    6.1, AMI* = 49.3, |M|* =     43\n",
      "[MinCut    ] <AMI> = 29.4 ±  9.9, <|M|> =  118.6 ±   24.6, AMI* = 76.1, |M|* =      6\n",
      "[Ortho     ] <AMI> = 32.0 ±  1.1, <|M|> =  101.7 ±   11.2, AMI* = 31.8, |M|* =    129\n",
      "[DMoN      ] <AMI> = 34.7 ±  3.5, <|M|> =   76.3 ±    6.7, AMI* = 32.3, |M|* =     88\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 52.7 ±  2.7, <|M|> =   14.9 ±    1.8, AMI* = 55.3, |M|* =     16\n",
      "[NOCD      ] <AMI> = 48.3 ±  1.5, <|M|> =   29.9 ±    4.3, AMI* = 48.8, |M|* =     31\n",
      "[DiffPool  ] <AMI> = 41.0 ±  3.9, <|M|> =    6.6 ±    1.1, AMI* = 45.8, |M|* =      8\n",
      "[MinCut    ] <AMI> = 51.7 ±  5.4, <|M|> =    6.1 ±    6.7, AMI* = 47.8, |M|* =     36\n",
      "[Ortho     ] <AMI> = 25.0 ±  0.7, <|M|> =  185.8 ±    1.0, AMI* = 23.8, |M|* =    186\n",
      "[DMoN      ] <AMI> = 29.8 ±  0.4, <|M|> =  185.9 ±    0.3, AMI* = 30.5, |M|* =    186\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 50.3 ±  1.4, <|M|> =   73.0 ±    8.0, AMI* = 48.9, |M|* =     76\n",
      "[NOCD      ] <AMI> = 42.0 ±  0.7, <|M|> =   73.9 ±    7.3, AMI* = 41.2, |M|* =     75\n",
      "[DiffPool  ] <AMI> = 62.4 ±  3.6, <|M|> =   19.0 ±    3.3, AMI* = 59.7, |M|* =     22\n",
      "[MinCut    ] <AMI> = 32.2 ±  6.8, <|M|> =  157.0 ±   40.2, AMI* = 29.0, |M|* =    186\n",
      "[Ortho     ] <AMI> = 32.4 ±  1.0, <|M|> =  166.2 ±   15.9, AMI* = 30.0, |M|* =    186\n",
      "[DMoN      ] <AMI> = 33.4 ±  0.2, <|M|> =  186.0 ±    0.0, AMI* = 32.9, |M|* =    186\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 51.9 ±  2.2, <|M|> =   41.3 ±    6.1, AMI* = 50.3, |M|* =     42\n",
      "[NOCD      ] <AMI> = 42.4 ±  0.7, <|M|> =   55.7 ±    2.9, AMI* = 41.6, |M|* =     52\n",
      "[DiffPool  ] <AMI> = 59.2 ±  3.3, <|M|> =   15.8 ±    2.1, AMI* = 54.8, |M|* =     15\n",
      "[MinCut    ] <AMI> = 30.5 ±  2.4, <|M|> =  176.5 ±   24.6, AMI* = 29.4, |M|* =    186\n",
      "[Ortho     ] <AMI> = 34.4 ±  1.1, <|M|> =  109.5 ±   18.1, AMI* = 33.2, |M|* =    147\n",
      "[DMoN      ] <AMI> = 33.6 ±  0.2, <|M|> =  186.0 ±    0.0, AMI* = 33.7, |M|* =    186\n",
      "=====\n",
      "[Infomap   ] <AMI> = 26.7 ±  0.1, <|M|> = 1160.8 ±   11.4, AMI* = 27.0, |M|* =   1166\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 59.5 ±  8.2, <|M|> =    4.1 ±    0.7, AMI* = 58.6, |M|* =      5\n",
      "[NOCD      ] <AMI> =  7.2 ±  4.5, <|M|> =    5.0 ±    0.0, AMI* =  2.7, |M|* =      5\n",
      "[DiffPool  ] <AMI> = 17.2 ± 18.2, <|M|> =    3.5 ±    1.0, AMI* =  0.1, |M|* =      2\n",
      "[MinCut    ] <AMI> = 49.1 ±  3.4, <|M|> =    5.0 ±    0.0, AMI* = 48.9, |M|* =      5\n",
      "[Ortho     ] <AMI> = 42.6 ±  5.1, <|M|> =    5.0 ±    0.0, AMI* = 46.3, |M|* =      5\n",
      "[DMoN      ] <AMI> = 31.9 ± 19.4, <|M|> =    4.5 ±    0.9, AMI* = 47.6, |M|* =      5\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 58.2 ±  6.0, <|M|> =    5.0 ±    0.0, AMI* = 67.4, |M|* =      5\n",
      "[NOCD      ] <AMI> = 56.8 ±  3.9, <|M|> =    5.0 ±    0.0, AMI* = 58.4, |M|* =      5\n",
      "[DiffPool  ] <AMI> = 30.4 ±  7.9, <|M|> =    5.0 ±    0.0, AMI* = 38.3, |M|* =      5\n",
      "[MinCut    ] <AMI> = 44.3 ±  4.8, <|M|> =    5.0 ±    0.0, AMI* = 45.0, |M|* =      5\n",
      "[Ortho     ] <AMI> = 29.7 ±  7.4, <|M|> =    5.0 ±    0.0, AMI* = 40.1, |M|* =      5\n",
      "[DMoN      ] <AMI> = 51.5 ±  3.9, <|M|> =    5.0 ±    0.0, AMI* = 49.1, |M|* =      5\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 45.0 ±  6.8, <|M|> =    3.9 ±    0.7, AMI* = 52.0, |M|* =      4\n",
      "[NOCD      ] <AMI> = 42.4 ±  4.9, <|M|> =    4.8 ±    0.4, AMI* = 48.8, |M|* =      5\n",
      "[DiffPool  ] <AMI> = 28.2 ± 12.2, <|M|> =    4.2 ±    0.9, AMI* = 14.0, |M|* =      3\n",
      "[MinCut    ] <AMI> = 46.1 ±  4.3, <|M|> =    5.0 ±    0.0, AMI* = 45.0, |M|* =      5\n",
      "[Ortho     ] <AMI> = 31.7 ±  5.4, <|M|> =    5.0 ±    0.0, AMI* = 28.9, |M|* =      5\n",
      "[DMoN      ] <AMI> = 39.5 ±  6.4, <|M|> =    5.0 ±    0.0, AMI* = 45.8, |M|* =      5\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 54.0 ±  6.4, <|M|> =    5.0 ±    0.0, AMI* = 59.2, |M|* =      5\n",
      "[NOCD      ] <AMI> = 46.5 ±  7.3, <|M|> =    5.0 ±    0.0, AMI* = 50.7, |M|* =      5\n",
      "[DiffPool  ] <AMI> = 50.6 ±  6.7, <|M|> =    5.0 ±    0.0, AMI* = 54.1, |M|* =      5\n",
      "[MinCut    ] <AMI> = 46.7 ±  5.3, <|M|> =    5.0 ±    0.0, AMI* = 56.1, |M|* =      5\n",
      "[Ortho     ] <AMI> = 42.0 ±  5.9, <|M|> =    5.0 ±    0.0, AMI* = 50.9, |M|* =      5\n",
      "[DMoN      ] <AMI> = 48.2 ±  6.1, <|M|> =    5.0 ±    0.2, AMI* = 52.8, |M|* =      5\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 49.6 ±  6.0, <|M|> =    5.0 ±    0.0, AMI* = 52.6, |M|* =      5\n",
      "[NOCD      ] <AMI> = 54.5 ±  4.7, <|M|> =    5.0 ±    0.0, AMI* = 59.2, |M|* =      5\n",
      "[DiffPool  ] <AMI> = 53.6 ±  9.0, <|M|> =    5.0 ±    0.0, AMI* = 44.8, |M|* =      5\n",
      "[MinCut    ] <AMI> = 46.2 ±  6.8, <|M|> =    5.0 ±    0.0, AMI* = 52.7, |M|* =      5\n",
      "[Ortho     ] <AMI> = 40.1 ±  6.3, <|M|> =    5.0 ±    0.0, AMI* = 43.7, |M|* =      5\n",
      "[DMoN      ] <AMI> = 47.2 ±  4.8, <|M|> =    5.0 ±    0.0, AMI* = 53.4, |M|* =      5\n",
      "=====\n",
      "[Infomap   ] <AMI> = 26.7 ±  0.1, <|M|> = 1160.8 ±   11.4, AMI* = 27.0, |M|* =   1166\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = physics, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(physics, directed = False, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/SherylHYX/pytorch_geometric_signed_directed/raw/main/datasets/cora_ml.npz\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Cora_ml():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 2879\n",
      "Number of classes: 7\n",
      "\n",
      "Data(x=[2995, 2879], edge_index=[2, 8416], y=[2995], edge_weight=[8416], train_mask=[2995, 10], val_mask=[2995, 10], test_mask=[2995, 10], seed_mask=[2995, 10])\n",
      "===========================================================================================================\n",
      "Number of edges: 8416\n",
      "Average node degree: 2.8\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Mixing µ = 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Cora_ml(root = \"data/Cora-ML\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "dataset.name = \"Cora-ML-Directed\"\n",
    "\n",
    "cora_ml = Data()\n",
    "cora_ml.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "cora_ml.x           = data.x\n",
    "cora_ml.y           = data.y\n",
    "cora_ml.num_classes = dataset.num_classes\n",
    "cora_ml.name        = \"Cora-ML\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(cora_ml, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 24.4 ± 11.9, <|M|> =   11.4 ±    2.5, AMI* = 39.2, |M|* =     12\n",
      "[NOCD      ] <AMI> =  3.3 ±  1.1, <|M|> =   24.8 ±    3.9, AMI* =  0.9, |M|* =     21\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.1, <|M|> =    1.0 ±    0.2, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> = 30.4 ±  1.2, <|M|> =   55.0 ±    0.0, AMI* = 30.8, |M|* =     55\n",
      "[Ortho     ] <AMI> = 15.6 ±  1.1, <|M|> =   34.5 ±    3.3, AMI* = 14.7, |M|* =     41\n",
      "[DMoN      ] <AMI> =  0.4 ±  0.8, <|M|> =    4.5 ±    6.2, AMI* =  0.1, |M|* =      4\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 34.5 ±  1.6, <|M|> =   48.3 ±    1.9, AMI* = 34.0, |M|* =     43\n",
      "[NOCD      ] <AMI> = 46.5 ±  1.4, <|M|> =   27.6 ±    1.7, AMI* = 47.6, |M|* =     28\n",
      "[DiffPool  ] <AMI> =  9.5 ±  1.2, <|M|> =   55.0 ±    0.0, AMI* =  8.3, |M|* =     55\n",
      "[MinCut    ] <AMI> = 39.6 ±  1.3, <|M|> =   38.1 ±    5.8, AMI* = 39.8, |M|* =     50\n",
      "[Ortho     ] <AMI> =  5.3 ±  0.5, <|M|> =   55.0 ±    0.0, AMI* =  5.7, |M|* =     55\n",
      "[DMoN      ] <AMI> = 36.2 ±  1.2, <|M|> =   55.0 ±    0.2, AMI* = 37.2, |M|* =     55\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 37.5 ±  1.9, <|M|> =   22.6 ±    2.7, AMI* = 38.6, |M|* =     26\n",
      "[NOCD      ] <AMI> = 43.3 ±  1.2, <|M|> =   24.9 ±    2.6, AMI* = 40.9, |M|* =     26\n",
      "[DiffPool  ] <AMI> = 31.6 ±  2.8, <|M|> =   15.5 ±    2.5, AMI* = 29.1, |M|* =     14\n",
      "[MinCut    ] <AMI> =  6.9 ±  4.5, <|M|> =   40.6 ±    6.0, AMI* =  3.2, |M|* =     35\n",
      "[Ortho     ] <AMI> = 28.7 ±  1.1, <|M|> =   55.0 ±    0.0, AMI* = 28.3, |M|* =     55\n",
      "[DMoN      ] <AMI> = 34.7 ±  1.5, <|M|> =   54.5 ±    0.6, AMI* = 33.7, |M|* =     54\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 36.4 ±  1.2, <|M|> =   54.3 ±    0.7, AMI* = 37.6, |M|* =     54\n",
      "[NOCD      ] <AMI> = 39.1 ±  1.0, <|M|> =   54.0 ±    0.8, AMI* = 39.5, |M|* =     53\n",
      "[DiffPool  ] <AMI> = 33.5 ±  1.2, <|M|> =   54.1 ±    0.9, AMI* = 32.6, |M|* =     54\n",
      "[MinCut    ] <AMI> = 26.2 ±  0.7, <|M|> =   55.0 ±    0.0, AMI* = 26.8, |M|* =     55\n",
      "[Ortho     ] <AMI> = 19.2 ±  1.1, <|M|> =   55.0 ±    0.0, AMI* = 19.7, |M|* =     55\n",
      "[DMoN      ] <AMI> = 37.7 ±  0.9, <|M|> =   54.8 ±    0.4, AMI* = 40.3, |M|* =     55\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 39.1 ±  2.1, <|M|> =   45.4 ±    2.8, AMI* = 42.3, |M|* =     44\n",
      "[NOCD      ] <AMI> = 40.6 ±  1.1, <|M|> =   51.1 ±    1.7, AMI* = 38.0, |M|* =     52\n",
      "[DiffPool  ] <AMI> = 29.6 ±  2.2, <|M|> =   54.2 ±    0.7, AMI* = 29.0, |M|* =     54\n",
      "[MinCut    ] <AMI> = 35.9 ±  0.7, <|M|> =   55.0 ±    0.0, AMI* = 36.1, |M|* =     55\n",
      "[Ortho     ] <AMI> = 16.3 ±  1.1, <|M|> =   55.0 ±    0.0, AMI* = 16.0, |M|* =     55\n",
      "[DMoN      ] <AMI> = 40.5 ±  1.0, <|M|> =   54.8 ±    0.4, AMI* = 40.7, |M|* =     55\n",
      "=====\n",
      "[Infomap   ] <AMI> = 35.7 ±  0.3, <|M|> =  287.4 ±    3.8, AMI* = 35.6, |M|* =    292\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  5.3 ±  9.1, <|M|> =    2.6 ±    0.8, AMI* = 38.3, |M|* =      4\n",
      "[NOCD      ] <AMI> =  3.6 ±  1.2, <|M|> =    7.0 ±    0.0, AMI* =  2.4, |M|* =      7\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.0 ±    0.0, AMI* =  0.0, |M|* =      1\n",
      "[MinCut    ] <AMI> = 33.7 ±  3.4, <|M|> =    7.0 ±    0.0, AMI* = 39.1, |M|* =      7\n",
      "[Ortho     ] <AMI> = 12.7 ±  3.7, <|M|> =    6.1 ±    1.4, AMI* = 21.6, |M|* =      7\n",
      "[DMoN      ] <AMI> = 18.7 ± 12.0, <|M|> =    6.0 ±    1.8, AMI* = 32.7, |M|* =      7\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 24.6 ±  2.9, <|M|> =    7.0 ±    0.0, AMI* = 27.2, |M|* =      7\n",
      "[NOCD      ] <AMI> = 39.3 ±  5.3, <|M|> =    7.0 ±    0.2, AMI* = 47.3, |M|* =      7\n",
      "[DiffPool  ] <AMI> =  5.1 ±  1.0, <|M|> =    7.0 ±    0.0, AMI* =  5.3, |M|* =      7\n",
      "[MinCut    ] <AMI> = 33.2 ±  4.7, <|M|> =    7.0 ±    0.0, AMI* = 34.7, |M|* =      7\n",
      "[Ortho     ] <AMI> =  4.3 ±  1.1, <|M|> =    7.0 ±    0.0, AMI* =  3.6, |M|* =      7\n",
      "[DMoN      ] <AMI> = 34.2 ±  3.5, <|M|> =    7.0 ±    0.2, AMI* = 31.3, |M|* =      7\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 25.0 ±  3.5, <|M|> =    5.6 ±    0.8, AMI* = 25.1, |M|* =      6\n",
      "[NOCD      ] <AMI> = 34.5 ±  3.9, <|M|> =    6.4 ±    0.6, AMI* = 40.7, |M|* =      6\n",
      "[DiffPool  ] <AMI> = 12.5 ±  3.8, <|M|> =    3.3 ±    0.9, AMI* =  6.7, |M|* =      2\n",
      "[MinCut    ] <AMI> = 22.0 ±  2.4, <|M|> =    7.0 ±    0.0, AMI* = 24.2, |M|* =      7\n",
      "[Ortho     ] <AMI> = 17.6 ±  2.6, <|M|> =    7.0 ±    0.0, AMI* = 18.7, |M|* =      7\n",
      "[DMoN      ] <AMI> = 27.4 ±  2.4, <|M|> =    7.0 ±    0.0, AMI* = 29.0, |M|* =      7\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 26.5 ±  2.8, <|M|> =    7.0 ±    0.0, AMI* = 27.5, |M|* =      7\n",
      "[NOCD      ] <AMI> = 24.6 ± 11.2, <|M|> =    7.0 ±    0.0, AMI* = 34.5, |M|* =      7\n",
      "[DiffPool  ] <AMI> = 22.5 ±  3.1, <|M|> =    7.0 ±    0.0, AMI* = 29.1, |M|* =      7\n",
      "[MinCut    ] <AMI> = 28.2 ±  3.2, <|M|> =    7.0 ±    0.0, AMI* = 31.2, |M|* =      7\n",
      "[Ortho     ] <AMI> = 19.1 ±  3.2, <|M|> =    7.0 ±    0.0, AMI* = 18.6, |M|* =      7\n",
      "[DMoN      ] <AMI> = 33.8 ±  3.5, <|M|> =    7.0 ±    0.2, AMI* = 34.5, |M|* =      7\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 26.2 ±  2.8, <|M|> =    7.0 ±    0.0, AMI* = 30.2, |M|* =      7\n",
      "[NOCD      ] <AMI> = 36.7 ±  2.8, <|M|> =    7.0 ±    0.0, AMI* = 41.2, |M|* =      7\n",
      "[DiffPool  ] <AMI> = 17.1 ±  2.9, <|M|> =    7.0 ±    0.0, AMI* = 20.2, |M|* =      7\n",
      "[MinCut    ] <AMI> = 29.4 ±  3.7, <|M|> =    7.0 ±    0.0, AMI* = 33.0, |M|* =      7\n",
      "[Ortho     ] <AMI> = 15.9 ±  3.2, <|M|> =    7.0 ±    0.0, AMI* = 18.4, |M|* =      7\n",
      "[DMoN      ] <AMI> = 35.6 ±  3.8, <|M|> =    7.0 ±    0.0, AMI* = 42.6, |M|* =      7\n",
      "=====\n",
      "[Infomap   ] <AMI> = 35.7 ±  0.3, <|M|> =  287.4 ±    3.8, AMI* = 35.6, |M|* =    292\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = cora_ml, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(cora_ml, directed = True, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiki CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/pmernyei/wiki-cs-dataset/raw/master/dataset/data.json\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: WikiCS():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 300\n",
      "Number of classes: 10\n",
      "\n",
      "Data(x=[11701, 300], edge_index=[2, 297110], y=[11701], train_mask=[11701, 20], val_mask=[11701, 20], test_mask=[11701], stopping_mask=[11701, 20])\n",
      "===========================================================================================================\n",
      "Number of edges: 297110\n",
      "Average node degree: 25.4\n",
      "Has isolated nodes: True\n",
      "Has self-loops: True\n",
      "Is undirected: False\n",
      "Mixing µ = 0.34\n"
     ]
    }
   ],
   "source": [
    "dataset = WikiCS(root = \"data/WikiCS\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "dataset.name = \"WikiCS-Directed\"\n",
    "\n",
    "wiki_cs = Data()\n",
    "wiki_cs.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "wiki_cs.x           = data.x\n",
    "wiki_cs.y           = data.y\n",
    "wiki_cs.num_classes = dataset.num_classes\n",
    "wiki_cs.name        = \"WikiCS\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(wiki_cs, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 41.9 ±  2.3, <|M|> =   17.0 ±    1.7, AMI* = 40.5, |M|* =     19\n",
      "[NOCD      ] <AMI> = 10.8 ±  3.1, <|M|> =   11.2 ±    0.9, AMI* = 13.2, |M|* =     12\n",
      "[DiffPool  ] <AMI> =  2.4 ±  2.1, <|M|> =    4.4 ±    1.0, AMI* =  3.7, |M|* =      3\n",
      "[MinCut    ] <AMI> = 16.0 ±  1.4, <|M|> =   48.5 ±    4.9, AMI* = 14.9, |M|* =     42\n",
      "[Ortho     ] <AMI> = 29.6 ±  0.9, <|M|> =   33.2 ±    2.6, AMI* = 30.3, |M|* =     37\n",
      "[DMoN      ] <AMI> =  4.8 ±  3.9, <|M|> =   10.9 ±    5.6, AMI* =  5.3, |M|* =      6\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 43.9 ±  2.4, <|M|> =   12.3 ±    1.3, AMI* = 41.6, |M|* =     16\n",
      "[NOCD      ] <AMI> = 40.9 ±  1.2, <|M|> =   28.3 ±    2.0, AMI* = 41.5, |M|* =     28\n",
      "[DiffPool  ] <AMI> = 25.8 ±  2.6, <|M|> =   10.0 ±    1.4, AMI* = 24.4, |M|* =      8\n",
      "[MinCut    ] <AMI> = 28.1 ±  4.2, <|M|> =  101.4 ±   19.2, AMI* = 28.6, |M|* =    108\n",
      "[Ortho     ] <AMI> = 28.8 ±  0.9, <|M|> =   41.0 ±    6.2, AMI* = 29.5, |M|* =     52\n",
      "[DMoN      ] <AMI> = 31.5 ±  8.0, <|M|> =   92.9 ±   27.1, AMI* = 36.2, |M|* =    107\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 34.9 ±  4.5, <|M|> =    6.8 ±    1.7, AMI* = 40.5, |M|* =      9\n",
      "[NOCD      ] <AMI> = 37.6 ±  1.1, <|M|> =   45.7 ±    5.1, AMI* = 36.2, |M|* =     44\n",
      "[DiffPool  ] <AMI> = 11.3 ±  3.1, <|M|> =    4.7 ±    1.0, AMI* =  8.9, |M|* =      3\n",
      "[MinCut    ] <AMI> =  1.3 ±  6.2, <|M|> =    4.0 ±   14.5, AMI* = 31.8, |M|* =     75\n",
      "[Ortho     ] <AMI> = 29.4 ±  0.6, <|M|> =  107.5 ±    0.8, AMI* = 29.8, |M|* =    108\n",
      "[DMoN      ] <AMI> = 29.7 ±  0.8, <|M|> =   97.2 ±    4.0, AMI* = 30.3, |M|* =    100\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 41.1 ±  3.2, <|M|> =   17.5 ±    2.4, AMI* = 41.5, |M|* =     21\n",
      "[NOCD      ] <AMI> = 44.2 ±  0.6, <|M|> =   33.8 ±    3.9, AMI* = 43.5, |M|* =     32\n",
      "[DiffPool  ] <AMI> = 35.7 ±  3.8, <|M|> =    7.7 ±    1.4, AMI* = 27.9, |M|* =      5\n",
      "[MinCut    ] <AMI> = 32.1 ±  0.5, <|M|> =  108.0 ±    0.0, AMI* = 31.3, |M|* =    108\n",
      "[Ortho     ] <AMI> = 32.1 ±  0.5, <|M|> =  108.0 ±    0.0, AMI* = 31.1, |M|* =    108\n",
      "[DMoN      ] <AMI> = 36.7 ±  0.4, <|M|> =  108.0 ±    0.0, AMI* = 37.2, |M|* =    108\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 44.8 ±  2.2, <|M|> =   17.1 ±    2.0, AMI* = 45.5, |M|* =     18\n",
      "[NOCD      ] <AMI> = 42.4 ±  0.4, <|M|> =   46.6 ±    2.7, AMI* = 42.0, |M|* =     45\n",
      "[DiffPool  ] <AMI> = 38.1 ±  2.8, <|M|> =   10.1 ±    1.2, AMI* = 38.2, |M|* =     11\n",
      "[MinCut    ] <AMI> = 32.3 ±  0.5, <|M|> =  108.0 ±    0.0, AMI* = 31.9, |M|* =    108\n",
      "[Ortho     ] <AMI> = 31.7 ±  0.5, <|M|> =  105.1 ±    1.6, AMI* = 31.4, |M|* =    108\n",
      "[DMoN      ] <AMI> = 36.4 ±  0.4, <|M|> =  108.0 ±    0.0, AMI* = 36.8, |M|* =    108\n",
      "=====\n",
      "[Infomap   ] <AMI> = 37.9 ±  0.2, <|M|> =  747.0 ±    8.4, AMI* = 38.0, |M|* =    740\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 11.7 ± 11.0, <|M|> =    3.0 ±    0.9, AMI* = 31.7, |M|* =      5\n",
      "[NOCD      ] <AMI> =  9.4 ±  2.5, <|M|> =    9.5 ±    0.7, AMI* =  8.8, |M|* =      8\n",
      "[DiffPool  ] <AMI> =  0.0 ±  0.0, <|M|> =    2.5 ±    0.6, AMI* = -0.0, |M|* =      2\n",
      "[MinCut    ] <AMI> = 19.4 ± 10.4, <|M|> =    6.0 ±    2.4, AMI* = 31.0, |M|* =     10\n",
      "[Ortho     ] <AMI> = 18.7 ±  5.0, <|M|> =    7.8 ±    1.7, AMI* = 24.1, |M|* =     10\n",
      "[DMoN      ] <AMI> =  9.1 ± 12.9, <|M|> =    5.1 ±    3.1, AMI* = 31.4, |M|* =     10\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 38.7 ±  4.8, <|M|> =    7.6 ±    1.1, AMI* = 42.0, |M|* =     10\n",
      "[NOCD      ] <AMI> = 38.1 ±  2.5, <|M|> =    9.8 ±    0.6, AMI* = 40.6, |M|* =     10\n",
      "[DiffPool  ] <AMI> = 19.3 ±  3.4, <|M|> =    6.2 ±    0.9, AMI* = 12.0, |M|* =      7\n",
      "[MinCut    ] <AMI> = 37.4 ±  2.3, <|M|> =   10.0 ±    0.0, AMI* = 39.9, |M|* =     10\n",
      "[Ortho     ] <AMI> = 25.1 ±  1.8, <|M|> =   10.0 ±    0.0, AMI* = 24.3, |M|* =     10\n",
      "[DMoN      ] <AMI> = 38.6 ±  3.0, <|M|> =   10.0 ±    0.0, AMI* = 39.1, |M|* =     10\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 29.7 ±  8.1, <|M|> =    4.9 ±    1.2, AMI* = 34.4, |M|* =      6\n",
      "[NOCD      ] <AMI> = 27.9 ±  3.2, <|M|> =    9.4 ±    0.6, AMI* = 32.0, |M|* =      8\n",
      "[DiffPool  ] <AMI> =  5.1 ±  3.0, <|M|> =    3.9 ±    1.3, AMI* =  6.3, |M|* =      4\n",
      "[MinCut    ] <AMI> = 24.8 ± 11.9, <|M|> =    8.4 ±    3.4, AMI* = 31.8, |M|* =     10\n",
      "[Ortho     ] <AMI> = 23.2 ±  2.6, <|M|> =   10.0 ±    0.0, AMI* = 23.4, |M|* =     10\n",
      "[DMoN      ] <AMI> = 22.2 ±  3.5, <|M|> =   10.0 ±    0.2, AMI* = 26.7, |M|* =     10\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 36.9 ±  4.2, <|M|> =    8.7 ±    0.9, AMI* = 46.6, |M|* =     10\n",
      "[NOCD      ] <AMI> = 42.3 ±  2.2, <|M|> =   10.0 ±    0.0, AMI* = 44.9, |M|* =     10\n",
      "[DiffPool  ] <AMI> = 29.3 ±  4.8, <|M|> =    5.5 ±    1.0, AMI* = 28.8, |M|* =      6\n",
      "[MinCut    ] <AMI> = 37.5 ±  1.9, <|M|> =   10.0 ±    0.0, AMI* = 37.2, |M|* =     10\n",
      "[Ortho     ] <AMI> = 35.7 ±  1.9, <|M|> =   10.0 ±    0.0, AMI* = 37.6, |M|* =     10\n",
      "[DMoN      ] <AMI> = 38.2 ±  2.2, <|M|> =   10.0 ±    0.0, AMI* = 37.5, |M|* =     10\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 41.0 ±  2.5, <|M|> =    9.4 ±    0.6, AMI* = 43.7, |M|* =     10\n",
      "[NOCD      ] <AMI> = 41.7 ±  2.3, <|M|> =   10.0 ±    0.0, AMI* = 42.5, |M|* =     10\n",
      "[DiffPool  ] <AMI> = 33.5 ±  3.2, <|M|> =    7.0 ±    0.8, AMI* = 38.4, |M|* =      8\n",
      "[MinCut    ] <AMI> = 37.1 ±  1.9, <|M|> =   10.0 ±    0.0, AMI* = 39.2, |M|* =     10\n",
      "[Ortho     ] <AMI> = 34.2 ±  2.2, <|M|> =   10.0 ±    0.0, AMI* = 29.1, |M|* =     10\n",
      "[DMoN      ] <AMI> = 38.6 ±  2.1, <|M|> =   10.0 ±    0.0, AMI* = 40.4, |M|* =     10\n",
      "=====\n",
      "[Infomap   ] <AMI> = 37.9 ±  0.2, <|M|> =  747.0 ±    8.4, AMI* = 38.0, |M|* =    740\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = wiki_cs, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(wiki_cs, directed = True, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ogb-arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PygNodePropPredDataset():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 128\n",
      "Number of classes: 40\n",
      "\n",
      "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])\n",
      "===========================================================================================================\n",
      "Number of edges: 1166243\n",
      "Average node degree: 6.9\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Mixing µ = 0.35\n"
     ]
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(root = \"data/ogbn-arxiv\", name=\"ogbn-arxiv\")\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "get_dataset_stats(dataset, data)\n",
    "\n",
    "arxiv = Data()\n",
    "arxiv.edge_index  = torch.sparse_coo_tensor(indices = data.edge_index, values = torch.FloatTensor(data.num_edges*[1]), size = (data.num_nodes, data.num_nodes)).coalesce()\n",
    "arxiv.x           = data.x\n",
    "arxiv.y           = data.y.reshape(-1)\n",
    "arxiv.num_classes = dataset.num_classes\n",
    "arxiv.name        = \"arxiv\"\n",
    "\n",
    "print(f\"Mixing µ = {get_mixing(arxiv, directed = False):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  4.7 ±  7.7, <|M|> =    2.4 ±    1.6, AMI* = 20.6, |M|* =      6\n",
      "[NOCD      ] <AMI> =  4.2 ±  2.5, <|M|> =   12.9 ±    2.8, AMI* =  6.5, |M|* =     19\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.47 GiB is free. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 234.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> =  3.8 ±  3.5, <|M|> =   81.6 ±   93.0, AMI* =  0.0, |M|* =      1\n",
      "[Ortho     ] <AMI> = 19.1 ±  0.5, <|M|> =   32.8 ±    3.4, AMI* = 18.8, |M|* =     40\n",
      "[DMoN      ] <AMI> =  4.0 ±  3.6, <|M|> =    7.6 ±    6.4, AMI* = 11.6, |M|* =     23\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 32.9 ±  1.3, <|M|> =   29.5 ±    4.4, AMI* = 33.6, |M|* =     29\n",
      "[NOCD      ] <AMI> =  9.7 ±  2.3, <|M|> =  145.4 ±   41.7, AMI* =  2.6, |M|* =     69\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.91 GiB is free. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 491.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> =  8.0 ±  2.7, <|M|> =  155.0 ±   49.5, AMI* =  0.0, |M|* =      1\n",
      "[Ortho     ] <AMI> = 18.5 ±  0.4, <|M|> =  187.7 ±   18.9, AMI* = 18.4, |M|* =    218\n",
      "[DMoN      ] <AMI> = 12.8 ±  1.7, <|M|> =  118.9 ±   13.2, AMI* = 13.8, |M|* =    120\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 28.0 ±  2.8, <|M|> =    5.5 ±    1.3, AMI* = 31.9, |M|* =      5\n",
      "[NOCD      ] <AMI> = 28.7 ±  1.2, <|M|> =   78.5 ±   15.6, AMI* = 30.2, |M|* =     50\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 13.13 GiB is free. Of the allocated memory 8.58 GiB is allocated by PyTorch, and 1013.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 13.13 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 12.71 GiB is free. Of the allocated memory 8.32 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 10.3 ±  7.3, <|M|> =   10.5 ±    4.2, AMI* = 20.3, |M|* =      8\n",
      "[Ortho     ] <AMI> = 24.1 ±  0.8, <|M|> =  170.2 ±   22.4, AMI* = 25.3, |M|* =    215\n",
      "[DMoN      ] <AMI> = 26.2 ±  3.2, <|M|> =  301.8 ±   77.3, AMI* = 29.3, |M|* =    362\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 42.3 ±  1.7, <|M|> =   34.4 ±    7.0, AMI* = 44.4, |M|* =     34\n",
      "[NOCD      ] <AMI> = 43.8 ±  0.4, <|M|> =   69.0 ±    6.5, AMI* = 43.9, |M|* =     78\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.82 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 513.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 17.79 GiB is free. Of the allocated memory 4.38 GiB is allocated by PyTorch, and 535.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 33.9 ±  4.7, <|M|> =   97.4 ±   20.9, AMI* = 35.2, |M|* =     91\n",
      "[Ortho     ] <AMI> = 34.3 ±  0.7, <|M|> =  253.8 ±   68.3, AMI* = 33.4, |M|* =    374\n",
      "[DMoN      ] <AMI> = 38.4 ±  0.2, <|M|> =  412.0 ±    0.0, AMI* = 38.4, |M|* =    412\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 43.6 ±  1.0, <|M|> =   39.5 ±    4.4, AMI* = 44.5, |M|* =     52\n",
      "[NOCD      ] <AMI> = 43.1 ±  0.3, <|M|> =   68.0 ±    6.6, AMI* = 43.0, |M|* =     73\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 16.61 GiB is free. Of the allocated memory 5.46 GiB is allocated by PyTorch, and 645.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 33.0 ±  1.5, <|M|> =  379.5 ±   33.7, AMI* = 29.2, |M|* =    412\n",
      "[Ortho     ] <AMI> = 24.9 ±  0.3, <|M|> =  379.8 ±    4.6, AMI* = 25.0, |M|* =    389\n",
      "[DMoN      ] <AMI> = 38.1 ±  0.3, <|M|> =  412.0 ±    0.0, AMI* = 38.2, |M|* =    412\n",
      "=====\n",
      "[Infomap   ] <AMI> = 35.9 ±  0.1, <|M|> = 4840.0 ±   22.4, AMI* = 35.8, |M|* =   4840\n",
      "lin\n",
      "=====\n",
      "[Neuromap  ] <AMI> =  0.0 ±  0.0, <|M|> =    1.2 ±    0.4, AMI* =  0.0, |M|* =      1\n",
      "[NOCD      ] <AMI> =  4.0 ±  1.4, <|M|> =   10.1 ±    1.3, AMI* =  7.0, |M|* =     13\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 22.43 GiB is free. Of the allocated memory 257.88 MiB is allocated by PyTorch, and 20.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> =  3.8 ±  2.0, <|M|> =   10.8 ±    9.1, AMI* =  2.2, |M|* =      2\n",
      "[Ortho     ] <AMI> = 17.1 ±  1.1, <|M|> =   15.0 ±    1.7, AMI* = 17.6, |M|* =     18\n",
      "[DMoN      ] <AMI> =  0.8 ±  1.1, <|M|> =    3.5 ±    3.2, AMI* =  1.9, |M|* =      7\n",
      "mlp\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 30.3 ±  1.8, <|M|> =   12.0 ±    2.4, AMI* = 32.2, |M|* =     10\n",
      "[NOCD      ] <AMI> = 28.9 ±  0.5, <|M|> =   23.9 ±    3.6, AMI* = 29.8, |M|* =     24\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 295.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 21.6 ±  8.1, <|M|> =   36.2 ±    4.6, AMI* = 29.6, |M|* =     40\n",
      "[Ortho     ] <AMI> = 17.9 ±  0.5, <|M|> =   35.6 ±    1.8, AMI* = 17.8, |M|* =     39\n",
      "[DMoN      ] <AMI> = 29.7 ±  0.4, <|M|> =   40.0 ±    0.0, AMI* = 30.6, |M|* =     40\n",
      "gin\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 22.2 ±  2.5, <|M|> =    4.8 ±    1.5, AMI* = 28.3, |M|* =      5\n",
      "[NOCD      ] <AMI> = 23.7 ±  1.2, <|M|> =   20.5 ±    3.2, AMI* = 24.2, |M|* =     14\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 19.98 GiB is free. Of the allocated memory 2.42 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 14.2 ±  4.6, <|M|> =    8.9 ±    3.8, AMI* = 19.7, |M|* =      2\n",
      "[Ortho     ] <AMI> = 25.5 ±  1.2, <|M|> =   40.0 ±    0.0, AMI* = 27.8, |M|* =     40\n",
      "[DMoN      ] <AMI> = 27.1 ±  1.6, <|M|> =   39.5 ±    1.0, AMI* = 28.2, |M|* =     40\n",
      "gcn\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 40.2 ±  1.6, <|M|> =   16.2 ±    2.3, AMI* = 42.4, |M|* =     15\n",
      "[NOCD      ] <AMI> = 43.6 ±  0.5, <|M|> =   36.2 ±    1.4, AMI* = 43.6, |M|* =     37\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 21.12 GiB is free. Of the allocated memory 1.35 GiB is allocated by PyTorch, and 241.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 37.7 ±  1.4, <|M|> =   37.1 ±    5.4, AMI* = 37.2, |M|* =     40\n",
      "[Ortho     ] <AMI> = 34.6 ±  0.8, <|M|> =   40.0 ±    0.0, AMI* = 34.3, |M|* =     40\n",
      "[DMoN      ] <AMI> = 40.6 ±  0.4, <|M|> =   40.0 ±    0.0, AMI* = 40.9, |M|* =     40\n",
      "sage\n",
      "=====\n",
      "[Neuromap  ] <AMI> = 39.9 ±  1.6, <|M|> =   13.0 ±    1.1, AMI* = 42.6, |M|* =     14\n",
      "[NOCD      ] <AMI> = 42.9 ±  0.4, <|M|> =   31.8 ±    1.8, AMI* = 42.9, |M|* =     34\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 106.83 GiB. GPU 0 has a total capacity of 24.00 GiB of which 20.71 GiB is free. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 295.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[MinCut    ] <AMI> = 37.3 ±  0.5, <|M|> =   40.0 ±    0.0, AMI* = 38.2, |M|* =     40\n",
      "[Ortho     ] <AMI> = 29.5 ±  0.6, <|M|> =   39.9 ±    0.3, AMI* = 29.7, |M|* =     40\n",
      "[DMoN      ] <AMI> = 40.2 ±  0.4, <|M|> =   40.0 ±    0.0, AMI* = 40.6, |M|* =     40\n",
      "=====\n",
      "[Infomap   ] <AMI> = 35.9 ±  0.1, <|M|> = 4840.0 ±   22.4, AMI* = 35.8, |M|* =   4840\n"
     ]
    }
   ],
   "source": [
    "for fixed_size_arch in [False, True]:\n",
    "    run(data = arxiv, methods = [Neuromap, NOCD, DiffPool, MinCut, Ortho, DMoN], num_trials = 25, verbose = False, fixed_size_arch = fixed_size_arch)\n",
    "    print(\"=====\")\n",
    "    run_infomap(arxiv, directed = True, num_trials = 25, fixed_size_arch = fixed_size_arch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
